{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3a93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849733b",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The reward model is pretrained model for summarization task with a randomly initialized linear head on top. So in our T5 model, let's try to add a linear head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f4e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 19:58:34.341758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:34.355569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:34.356016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:34.356981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 19:58:34.358235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:34.358650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:34.359057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:35.115260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:35.115678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:35.116113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 19:58:35.116486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15389 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tft5_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shared (Embedding)          multiple                  16449536  \n",
      "                                                                 \n",
      " encoder (TFT5MainLayer)     multiple                  35330816  \n",
      "                                                                 \n",
      " decoder (TFT5MainLayer)     multiple                  41625344  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,506,624\n",
      "Trainable params: 60,506,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Pretrained supervised T5 model\n",
    "tf.keras.backend.clear_session()\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c3ca86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration at 0x7fdd97951910>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1386c803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.embedding.Embedding at 0x7f9684020150>,\n",
       " <transformers.models.t5.modeling_tf_t5.TFT5MainLayer at 0x7f9684020650>,\n",
       " <transformers.models.t5.modeling_tf_t5.TFT5MainLayer at 0x7f9684020310>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd8e4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e40e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669d4997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 101), dtype=int32, numpy=\n",
       "array([[21603,    10,    37,    86,    89,  6105,   419,  8291,  1983,\n",
       "         1364,     7,  7744,  2672,  1358,     6,   533,   124,  1358,\n",
       "            6,    11,   827,  1358,     5,    94,    31,     7,     8,\n",
       "          167,  8299,  1041,    30,     3, 26074,     8,  3298,  5362,\n",
       "           16,   797,   892,     6,    84,    56,  5656,    95,   797,\n",
       "         2765,    11,   482,   207,    18,  8832,    53,     6,  7021,\n",
       "         2476,   640,     8,   684,     5,    94,    31,   195,  1364,\n",
       "            8, 11724,    11,   987,     8,  6173,    18,  1123,   138,\n",
       "          189,    63,    11, 11711,    12,   726,    70,  2725,   698,\n",
       "            5,   275,   150,    80,   492,   365,  1514, 31471,   399,\n",
       "          215,    56,   726,     3,     9, 23925,    72,    16,  5161,\n",
       "            5,     1]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([text], return_tensors=\"tf\", padding=True, truncation=True)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e1b75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration at 0x7f97207bae90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa482b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.t5.configuration_t5 import T5Config\n",
    "from transformers.models.t5.modeling_tf_t5 import TFT5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208e585a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5Model.\n",
      "\n",
      "All the layers of TFT5Model were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = T5Config()\n",
    "\n",
    "model_without_head = TFT5Model(config).from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa1dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c79189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be185dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87de3609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSeq2SeqModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 101, 512), dtype=float32, numpy=\n",
       "array([[[-0.46276543,  1.0959268 ,  1.0243176 , ...,  2.6208034 ,\n",
       "          1.530184  , -0.0862919 ],\n",
       "        [-0.47934574,  1.0995437 ,  1.0164989 , ...,  2.6417081 ,\n",
       "          1.5272915 , -0.13780792],\n",
       "        [-0.4515319 ,  1.071627  ,  1.0325024 , ...,  2.6534188 ,\n",
       "          1.5200558 , -0.11399219],\n",
       "        ...,\n",
       "        [-0.46786645,  1.0388124 ,  1.0414091 , ...,  2.6877446 ,\n",
       "          1.5250008 , -0.11594465],\n",
       "        [-0.48268214,  1.0611473 ,  1.0236026 , ...,  2.6838536 ,\n",
       "          1.5431606 , -0.11632806],\n",
       "        [-0.4720666 ,  1.0709583 ,  1.0015554 , ...,  2.674243  ,\n",
       "          1.5484025 , -0.12812552]]], dtype=float32)>, past_key_values=((<tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-0.12296635, -0.26068586,  0.02107891, ..., -0.4433809 ,\n",
       "          -0.7091241 , -1.2599609 ],\n",
       "         [-0.14442179, -0.32069674,  0.13090545, ..., -0.43308276,\n",
       "          -0.7551682 , -1.2974797 ],\n",
       "         [-0.23404047, -0.33701944,  0.03115335, ..., -0.4358471 ,\n",
       "          -0.72531503, -1.2427803 ],\n",
       "         ...,\n",
       "         [-0.13148364, -0.3659742 ,  0.03419256, ..., -0.46161228,\n",
       "          -0.63158435, -1.2329924 ],\n",
       "         [-0.12264374, -0.19052178,  0.01691836, ..., -0.4963969 ,\n",
       "          -0.7367959 , -1.3208522 ],\n",
       "         [-0.07630894, -0.28275156, -0.02783564, ..., -0.4649347 ,\n",
       "          -0.6955534 , -1.2724386 ]],\n",
       "\n",
       "        [[ 0.65966976, -0.05224702,  0.08832848, ...,  0.49061224,\n",
       "           1.5350257 ,  0.6550436 ],\n",
       "         [ 0.5499252 , -0.10161734,  0.08084923, ...,  0.45071697,\n",
       "           1.4537786 ,  0.7248357 ],\n",
       "         [ 0.60643053, -0.05406772,  0.09776378, ...,  0.41955817,\n",
       "           1.481367  ,  0.62155277],\n",
       "         ...,\n",
       "         [ 0.5456364 ,  0.03053081,  0.1408456 , ...,  0.44287288,\n",
       "           1.4867932 ,  0.72441226],\n",
       "         [ 0.44779074, -0.01882014,  0.12089378, ...,  0.53609025,\n",
       "           1.5073802 ,  0.6955606 ],\n",
       "         [ 0.5282674 ,  0.04172714,  0.1138044 , ...,  0.47846067,\n",
       "           1.5242147 ,  0.69339395]],\n",
       "\n",
       "        [[-1.4131459 , -1.0116267 , -0.2933712 , ...,  0.5181717 ,\n",
       "           0.49200475,  0.8887119 ],\n",
       "         [-1.33595   , -0.96283305, -0.24930747, ...,  0.46597475,\n",
       "           0.490331  ,  1.0074266 ],\n",
       "         [-1.4071753 , -0.96477073, -0.20465486, ...,  0.44018334,\n",
       "           0.532677  ,  0.915679  ],\n",
       "         ...,\n",
       "         [-1.3218637 , -0.94669825, -0.28943962, ...,  0.44012398,\n",
       "           0.49655294,  1.0335876 ],\n",
       "         [-1.2364707 , -0.8409627 , -0.30260408, ...,  0.5303187 ,\n",
       "           0.48644996,  1.0329485 ],\n",
       "         [-1.2603991 , -0.8662493 , -0.31516495, ...,  0.48267436,\n",
       "           0.47640228,  0.8951804 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2640861 , -0.3893581 , -0.97066855, ...,  1.0715605 ,\n",
       "           1.8195764 , -2.0696232 ],\n",
       "         [ 1.0917401 , -0.37252435, -0.98569936, ...,  1.0446898 ,\n",
       "           1.9452708 , -2.028497  ],\n",
       "         [ 1.249799  , -0.36645168, -1.0562859 , ...,  1.0514766 ,\n",
       "           1.9186914 , -2.1391397 ],\n",
       "         ...,\n",
       "         [ 1.2546853 , -0.33819205, -1.1165814 , ...,  1.1380621 ,\n",
       "           1.865913  , -2.0905046 ],\n",
       "         [ 1.2409669 , -0.35002097, -1.0420759 , ...,  1.1487441 ,\n",
       "           1.91349   , -2.0828228 ],\n",
       "         [ 1.3013322 , -0.3119756 , -1.0395304 , ...,  1.0400394 ,\n",
       "           1.8904136 , -2.0544486 ]],\n",
       "\n",
       "        [[ 0.53477955,  0.360248  , -1.4524091 , ...,  0.17251697,\n",
       "           1.4975523 , -1.035491  ],\n",
       "         [ 0.35896307,  0.3494339 , -1.5726138 , ...,  0.1660339 ,\n",
       "           1.4811485 , -1.0747993 ],\n",
       "         [ 0.47890353,  0.37866986, -1.5803664 , ...,  0.2018999 ,\n",
       "           1.4351351 , -1.0375988 ],\n",
       "         ...,\n",
       "         [ 0.48663545,  0.3662652 , -1.419523  , ...,  0.1448287 ,\n",
       "           1.4262835 , -1.0600445 ],\n",
       "         [ 0.35211527,  0.27319786, -1.5603662 , ...,  0.1327256 ,\n",
       "           1.525149  , -1.0698086 ],\n",
       "         [ 0.42134732,  0.27751565, -1.5613749 , ...,  0.11294784,\n",
       "           1.3780799 , -1.0806108 ]],\n",
       "\n",
       "        [[ 1.992152  ,  2.0806675 , -0.472701  , ..., -1.2296274 ,\n",
       "           0.99703777, -0.85915333],\n",
       "         [ 1.8726399 ,  2.028741  , -0.5116482 , ..., -1.1190724 ,\n",
       "           0.9710039 , -0.7861721 ],\n",
       "         [ 1.9331632 ,  2.0131435 , -0.45262414, ..., -1.1527121 ,\n",
       "           1.0327859 , -0.84594667],\n",
       "         ...,\n",
       "         [ 1.9291618 ,  1.9457444 , -0.52847755, ..., -1.1105478 ,\n",
       "           0.86713016, -0.82101315],\n",
       "         [ 1.9311366 ,  2.0556264 , -0.4756558 , ..., -1.1458114 ,\n",
       "           0.92487156, -0.80162954],\n",
       "         [ 2.0732884 ,  2.0178154 , -0.4837535 , ..., -1.1376654 ,\n",
       "           0.9795716 , -0.8518028 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-5.2687973e-02,  7.4246120e-01, -8.6009014e-01, ...,\n",
       "           1.7680526e-02,  3.3889955e-01, -1.6932287e+00],\n",
       "         [-7.4487716e-02,  6.7828435e-01, -9.0384412e-01, ...,\n",
       "           1.8692493e-02,  2.3638961e-01, -1.6478775e+00],\n",
       "         [-6.6621184e-02,  6.9905913e-01, -9.4077605e-01, ...,\n",
       "           7.8741789e-02,  2.2795156e-01, -1.6859105e+00],\n",
       "         ...,\n",
       "         [-8.5528523e-02,  6.4253968e-01, -9.8863453e-01, ...,\n",
       "          -3.4643352e-02,  3.0450699e-01, -1.7616279e+00],\n",
       "         [-1.8443763e-03,  6.6770029e-01, -9.0311861e-01, ...,\n",
       "           6.8123519e-02,  2.6787829e-01, -1.6634629e+00],\n",
       "         [-3.6611706e-02,  7.5150317e-01, -8.5990202e-01, ...,\n",
       "           8.8183284e-02,  3.3626083e-01, -1.7111197e+00]],\n",
       "\n",
       "        [[ 1.8774085e+00,  1.1083407e+00,  1.9500077e-01, ...,\n",
       "          -1.0457342e+00,  1.4687715e+00, -5.4947460e-01],\n",
       "         [ 1.9310396e+00,  1.1007603e+00,  2.0247310e-01, ...,\n",
       "          -1.0457803e+00,  1.5168736e+00, -4.9989101e-01],\n",
       "         [ 1.8921032e+00,  1.0454464e+00,  2.3067798e-01, ...,\n",
       "          -9.9398983e-01,  1.4478590e+00, -4.8618093e-01],\n",
       "         ...,\n",
       "         [ 1.8588037e+00,  1.0787717e+00,  1.5051745e-01, ...,\n",
       "          -9.4641733e-01,  1.4255767e+00, -5.1117444e-01],\n",
       "         [ 1.8367561e+00,  1.1457014e+00,  1.3146389e-01, ...,\n",
       "          -1.0184492e+00,  1.5405418e+00, -4.8663750e-01],\n",
       "         [ 1.9282014e+00,  1.0425549e+00,  1.5565822e-01, ...,\n",
       "          -1.0735229e+00,  1.4484514e+00, -5.0406837e-01]],\n",
       "\n",
       "        [[ 1.1847113e+00, -8.2611799e-02, -1.7592636e-01, ...,\n",
       "          -7.5794268e-01,  4.8325247e-01,  1.1276823e+00],\n",
       "         [ 1.3218156e+00, -7.6214761e-02, -2.1718070e-01, ...,\n",
       "          -7.0948756e-01,  4.0064359e-01,  1.0718957e+00],\n",
       "         [ 1.3501303e+00, -1.2015596e-01, -1.5765601e-01, ...,\n",
       "          -7.2951418e-01,  4.3963999e-01,  1.1162590e+00],\n",
       "         ...,\n",
       "         [ 1.3878175e+00, -1.0773027e-01, -2.5868434e-01, ...,\n",
       "          -7.5225937e-01,  3.3320495e-01,  1.1035924e+00],\n",
       "         [ 1.2969830e+00, -1.6063491e-01, -1.5460128e-01, ...,\n",
       "          -7.1878076e-01,  3.7675941e-01,  1.1260118e+00],\n",
       "         [ 1.3127635e+00, -1.0543287e-01, -2.6042062e-01, ...,\n",
       "          -7.6858497e-01,  4.1271284e-01,  1.1428933e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4638665e-01, -1.0807613e+00, -3.8985509e-01, ...,\n",
       "          -8.7449908e-02,  1.1502265e+00, -2.5625068e-01],\n",
       "         [ 1.4552811e-01, -9.7083008e-01, -3.2844260e-01, ...,\n",
       "          -1.3553946e-01,  1.0716252e+00, -1.8458822e-01],\n",
       "         [ 1.5421891e-01, -1.0876653e+00, -3.8623089e-01, ...,\n",
       "          -8.2048640e-02,  1.1452188e+00, -2.8000465e-01],\n",
       "         ...,\n",
       "         [ 1.1943257e-01, -9.7379512e-01, -3.8417748e-01, ...,\n",
       "          -1.2375535e-01,  1.0949814e+00, -9.8748088e-02],\n",
       "         [ 1.9789597e-01, -1.0846539e+00, -4.0143254e-01, ...,\n",
       "          -1.4401406e-01,  1.1254961e+00, -2.1547377e-01],\n",
       "         [ 1.4885569e-01, -1.1375604e+00, -4.5548433e-01, ...,\n",
       "          -1.2917592e-01,  1.1337862e+00, -2.1633399e-01]],\n",
       "\n",
       "        [[ 1.1164812e+00, -1.0827038e+00,  8.7416983e-01, ...,\n",
       "          -9.9391520e-01, -8.1514412e-01,  3.0179662e-01],\n",
       "         [ 1.0052419e+00, -1.0829928e+00,  8.3751458e-01, ...,\n",
       "          -9.8292583e-01, -7.8065151e-01,  3.1505293e-01],\n",
       "         [ 1.0879881e+00, -9.6314752e-01,  8.1675768e-01, ...,\n",
       "          -9.9113077e-01, -7.3665470e-01,  3.4099931e-01],\n",
       "         ...,\n",
       "         [ 1.0903442e+00, -1.0782893e+00,  8.9668375e-01, ...,\n",
       "          -9.4798851e-01, -7.8496456e-01,  2.8996885e-01],\n",
       "         [ 9.9715078e-01, -9.7472525e-01,  8.8483703e-01, ...,\n",
       "          -1.0372355e+00, -8.1746429e-01,  1.9294679e-01],\n",
       "         [ 1.0115452e+00, -9.8314339e-01,  8.4421557e-01, ...,\n",
       "          -1.0086842e+00, -7.3330230e-01,  3.4139186e-01]],\n",
       "\n",
       "        [[ 4.4682431e-01, -1.4066784e+00, -3.1972575e-01, ...,\n",
       "           1.0159847e+00, -4.5310313e-01,  2.7701175e-01],\n",
       "         [ 4.7766334e-01, -1.4523970e+00, -2.5406259e-01, ...,\n",
       "           1.1336907e+00, -4.8264706e-01,  1.8284252e-01],\n",
       "         [ 4.7693121e-01, -1.4785914e+00, -2.6671970e-01, ...,\n",
       "           1.0849457e+00, -5.0126266e-01,  2.3279798e-01],\n",
       "         ...,\n",
       "         [ 4.1244754e-01, -1.4984820e+00, -3.0037248e-01, ...,\n",
       "           1.0430088e+00, -4.3924463e-01,  2.8696257e-01],\n",
       "         [ 4.2153919e-01, -1.4946383e+00, -2.7448100e-01, ...,\n",
       "           1.0439119e+00, -5.1021969e-01,  1.5737140e-01],\n",
       "         [ 4.8019010e-01, -1.4433281e+00, -1.6805804e-01, ...,\n",
       "           9.8326504e-01, -5.1418215e-01,  2.4337643e-01]]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.4025982 ,  0.14674008,  0.21637177, ...,  0.9962544 ,\n",
       "           1.2338452 ,  0.64714366],\n",
       "         [ 0.3460697 ,  0.1500282 ,  0.18165636, ...,  0.9680363 ,\n",
       "           1.2728021 ,  0.617159  ],\n",
       "         [ 0.35958743,  0.12844814,  0.18024033, ...,  0.98378605,\n",
       "           1.238919  ,  0.61949444],\n",
       "         ...,\n",
       "         [ 0.3887641 ,  0.14379634,  0.1885789 , ...,  0.9798232 ,\n",
       "           1.2549628 ,  0.6408349 ],\n",
       "         [ 0.36537695,  0.11761847,  0.20805335, ...,  1.0043633 ,\n",
       "           1.2232431 ,  0.5801781 ],\n",
       "         [ 0.38047466,  0.12105882,  0.21141571, ...,  0.9603587 ,\n",
       "           1.2494652 ,  0.6133835 ]],\n",
       "\n",
       "        [[ 1.2325873 ,  0.18985522,  1.410937  , ..., -1.2394677 ,\n",
       "           2.2849145 , -1.3616065 ],\n",
       "         [ 1.2147892 ,  0.19831032,  1.4161999 , ..., -1.2284393 ,\n",
       "           2.2778401 , -1.3760536 ],\n",
       "         [ 1.2101121 ,  0.17291063,  1.4200749 , ..., -1.1987839 ,\n",
       "           2.2746763 , -1.4111401 ],\n",
       "         ...,\n",
       "         [ 1.2099537 ,  0.1987015 ,  1.4016352 , ..., -1.1781334 ,\n",
       "           2.3203318 , -1.3805691 ],\n",
       "         [ 1.2369292 ,  0.20931575,  1.3682623 , ..., -1.1959729 ,\n",
       "           2.2649264 , -1.4080503 ],\n",
       "         [ 1.2191076 ,  0.18540713,  1.381964  , ..., -1.2113343 ,\n",
       "           2.2706943 , -1.4285026 ]],\n",
       "\n",
       "        [[-0.47442147,  0.8179685 , -2.1978753 , ...,  1.2772318 ,\n",
       "           0.6670469 ,  0.931981  ],\n",
       "         [-0.48111358,  0.82665944, -2.1670742 , ...,  1.2395574 ,\n",
       "           0.6817843 ,  0.9039804 ],\n",
       "         [-0.5157958 ,  0.83213115, -2.1836195 , ...,  1.2524701 ,\n",
       "           0.67386353,  0.9477282 ],\n",
       "         ...,\n",
       "         [-0.44967902,  0.81511277, -2.1838417 , ...,  1.2834071 ,\n",
       "           0.68501794,  0.93842834],\n",
       "         [-0.49983686,  0.83050346, -2.166183  , ...,  1.2639658 ,\n",
       "           0.67182803,  0.94606376],\n",
       "         [-0.4724513 ,  0.81752795, -2.156926  , ...,  1.2607033 ,\n",
       "           0.7402554 ,  0.94476897]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2081505 ,  2.298451  ,  0.5456084 , ..., -1.4427309 ,\n",
       "           0.7915007 ,  0.252493  ],\n",
       "         [-0.19169945,  2.3324275 ,  0.52389824, ..., -1.4051648 ,\n",
       "           0.7551824 ,  0.26225284],\n",
       "         [-0.20238495,  2.245625  ,  0.52738434, ..., -1.4253855 ,\n",
       "           0.7673816 ,  0.25776643],\n",
       "         ...,\n",
       "         [-0.22094494,  2.2667482 ,  0.5383189 , ..., -1.4188085 ,\n",
       "           0.76158893,  0.21563202],\n",
       "         [-0.20481902,  2.2625275 ,  0.5594709 , ..., -1.4615399 ,\n",
       "           0.7558996 ,  0.28014258],\n",
       "         [-0.19988704,  2.2838268 ,  0.5486587 , ..., -1.4230909 ,\n",
       "           0.73840123,  0.2789472 ]],\n",
       "\n",
       "        [[-0.03302637, -0.7595174 , -0.8597269 , ..., -1.7140281 ,\n",
       "           0.29301825, -0.8029177 ],\n",
       "         [-0.06334932, -0.7590637 , -0.84626424, ..., -1.7358942 ,\n",
       "           0.30682695, -0.8318761 ],\n",
       "         [-0.01622647, -0.73788327, -0.84036124, ..., -1.7026643 ,\n",
       "           0.2929219 , -0.82615   ],\n",
       "         ...,\n",
       "         [-0.05186979, -0.74075747, -0.81254095, ..., -1.7123177 ,\n",
       "           0.28841227, -0.81171167],\n",
       "         [-0.03268538, -0.75787956, -0.8354579 , ..., -1.687418  ,\n",
       "           0.28365636, -0.79214907],\n",
       "         [-0.0752819 , -0.75479317, -0.8312316 , ..., -1.7133253 ,\n",
       "           0.297887  , -0.8259649 ]],\n",
       "\n",
       "        [[-0.37106723, -0.9308394 ,  0.17081046, ..., -0.48755503,\n",
       "          -0.8545487 , -0.00239134],\n",
       "         [-0.3895005 , -0.91121703,  0.16886215, ..., -0.46502095,\n",
       "          -0.8755136 ,  0.03767031],\n",
       "         [-0.37338442, -0.93086195,  0.16822521, ..., -0.48444143,\n",
       "          -0.84550375,  0.01837373],\n",
       "         ...,\n",
       "         [-0.36007327, -0.95302373,  0.1454094 , ..., -0.4916704 ,\n",
       "          -0.8001584 , -0.01858079],\n",
       "         [-0.37816304, -0.90183735,  0.162891  , ..., -0.49240142,\n",
       "          -0.84345144, -0.01930523],\n",
       "         [-0.39750174, -0.91699696,  0.1582047 , ..., -0.46891868,\n",
       "          -0.8523005 , -0.00320476]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-0.1383414 , -3.22262   ,  0.42540434, ..., -0.77026385,\n",
       "           0.7117155 ,  1.1048815 ],\n",
       "         [-0.12845904, -3.239825  ,  0.46197712, ..., -0.802058  ,\n",
       "           0.7513704 ,  1.0873432 ],\n",
       "         [-0.14923856, -3.220689  ,  0.4029499 , ..., -0.76375973,\n",
       "           0.70931154,  1.093069  ],\n",
       "         ...,\n",
       "         [-0.16311356, -3.2385566 ,  0.44202024, ..., -0.80004203,\n",
       "           0.75136185,  1.0780262 ],\n",
       "         [-0.16452676, -3.2616746 ,  0.440706  , ..., -0.79655063,\n",
       "           0.7213238 ,  1.0750775 ],\n",
       "         [-0.12753364, -3.2457988 ,  0.4144646 , ..., -0.77160686,\n",
       "           0.6832036 ,  1.0635648 ]],\n",
       "\n",
       "        [[ 0.7845403 , -0.25699937, -1.4903748 , ..., -0.31536832,\n",
       "           0.9403287 ,  0.15541737],\n",
       "         [ 0.7518962 , -0.22611636, -1.4758818 , ..., -0.28859556,\n",
       "           0.99788326,  0.13978358],\n",
       "         [ 0.79649884, -0.2623682 , -1.4538912 , ..., -0.29304355,\n",
       "           0.9915202 ,  0.13631329],\n",
       "         ...,\n",
       "         [ 0.77968895, -0.2777493 , -1.4770205 , ..., -0.29393843,\n",
       "           0.98430854,  0.16488758],\n",
       "         [ 0.7488016 , -0.28631735, -1.5112585 , ..., -0.3061449 ,\n",
       "           0.9639896 ,  0.13047561],\n",
       "         [ 0.7845948 , -0.2590437 , -1.4794407 , ..., -0.2979319 ,\n",
       "           0.98621863,  0.14640537]],\n",
       "\n",
       "        [[ 0.3859161 , -0.2346716 , -1.3080392 , ...,  1.093615  ,\n",
       "           0.73493516, -1.0449108 ],\n",
       "         [ 0.39576644, -0.1927368 , -1.2932453 , ...,  1.1334466 ,\n",
       "           0.7362438 , -1.0029584 ],\n",
       "         [ 0.41299865, -0.21800643, -1.2767475 , ...,  1.1419001 ,\n",
       "           0.7173514 , -1.0005945 ],\n",
       "         ...,\n",
       "         [ 0.3891076 , -0.1821742 , -1.2505983 , ...,  1.1483928 ,\n",
       "           0.7620027 , -1.0577887 ],\n",
       "         [ 0.37454134, -0.24085015, -1.2936046 , ...,  1.109497  ,\n",
       "           0.7714757 , -1.0190728 ],\n",
       "         [ 0.40058833, -0.23062587, -1.2537496 , ...,  1.1355097 ,\n",
       "           0.73963916, -1.0378493 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5359008 , -1.2985773 ,  1.3651314 , ...,  0.7727709 ,\n",
       "          -1.3233378 , -1.5405915 ],\n",
       "         [ 0.55233765, -1.2363176 ,  1.3771886 , ...,  0.78001857,\n",
       "          -1.3119819 , -1.5242171 ],\n",
       "         [ 0.58320427, -1.269403  ,  1.3624948 , ...,  0.75855947,\n",
       "          -1.3606018 , -1.5772073 ],\n",
       "         ...,\n",
       "         [ 0.54180825, -1.2760139 ,  1.3645604 , ...,  0.7616312 ,\n",
       "          -1.3079015 , -1.5659578 ],\n",
       "         [ 0.53790075, -1.2660146 ,  1.3549327 , ...,  0.7713846 ,\n",
       "          -1.3476894 , -1.5386893 ],\n",
       "         [ 0.57336605, -1.2575703 ,  1.346046  , ...,  0.79019284,\n",
       "          -1.3476319 , -1.575444  ]],\n",
       "\n",
       "        [[ 2.431229  , -0.7591226 ,  1.5453622 , ...,  1.0394017 ,\n",
       "           0.9027846 , -2.0960016 ],\n",
       "         [ 2.4388232 , -0.6997814 ,  1.5099168 , ...,  1.0454063 ,\n",
       "           0.84011114, -2.1250477 ],\n",
       "         [ 2.4173145 , -0.77105486,  1.5424674 , ...,  1.0863162 ,\n",
       "           0.82039046, -2.1286001 ],\n",
       "         ...,\n",
       "         [ 2.4132202 , -0.7682935 ,  1.5317707 , ...,  1.0402914 ,\n",
       "           0.83043325, -2.13025   ],\n",
       "         [ 2.430779  , -0.7325804 ,  1.5536647 , ...,  1.0681994 ,\n",
       "           0.84874624, -2.096612  ],\n",
       "         [ 2.4385998 , -0.74961495,  1.5587972 , ...,  1.0409576 ,\n",
       "           0.8456728 , -2.1027205 ]],\n",
       "\n",
       "        [[ 1.0798758 ,  0.32547575, -0.2383577 , ...,  1.3187244 ,\n",
       "          -0.3847788 ,  0.8403325 ],\n",
       "         [ 1.0353544 ,  0.33437514, -0.2519001 , ...,  1.3225482 ,\n",
       "          -0.3339342 ,  0.8271738 ],\n",
       "         [ 1.0815039 ,  0.3343839 , -0.27274334, ...,  1.3018432 ,\n",
       "          -0.35097456,  0.86469805],\n",
       "         ...,\n",
       "         [ 1.0737664 ,  0.33843762, -0.25006276, ...,  1.3052406 ,\n",
       "          -0.3564812 ,  0.8930182 ],\n",
       "         [ 1.0665123 ,  0.3480711 , -0.26603997, ...,  1.2452428 ,\n",
       "          -0.3230108 ,  0.88102204],\n",
       "         [ 1.064254  ,  0.39664206, -0.2513958 , ...,  1.2694376 ,\n",
       "          -0.37380978,  0.81727296]]]], dtype=float32)>), (<tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.2066626 ,  0.56879157,  3.1919334 , ..., -0.28543052,\n",
       "          -1.6318718 ,  1.2517793 ],\n",
       "         [ 0.16993731,  0.60830575,  3.1637104 , ..., -0.28981274,\n",
       "          -1.6097473 ,  1.2643957 ],\n",
       "         [ 0.23238105,  0.6111047 ,  3.1600783 , ..., -0.26001292,\n",
       "          -1.7102354 ,  1.2081797 ],\n",
       "         ...,\n",
       "         [ 0.21197712,  0.60879004,  3.1698709 , ..., -0.2577091 ,\n",
       "          -1.6564952 ,  1.2520108 ],\n",
       "         [ 0.22434938,  0.5991841 ,  3.2181687 , ..., -0.2329807 ,\n",
       "          -1.6302712 ,  1.2095922 ],\n",
       "         [ 0.2823847 ,  0.5775424 ,  3.1927633 , ..., -0.26172242,\n",
       "          -1.6503286 ,  1.2305263 ]],\n",
       "\n",
       "        [[ 2.3991392 ,  0.9140054 ,  0.3104657 , ...,  0.8884573 ,\n",
       "           0.6444513 ,  0.9512627 ],\n",
       "         [ 2.4609137 ,  0.8499348 ,  0.26247746, ...,  1.0392069 ,\n",
       "           0.6403522 ,  0.8932736 ],\n",
       "         [ 2.4015865 ,  0.9287487 ,  0.27471572, ...,  1.0443571 ,\n",
       "           0.6248741 ,  0.8888273 ],\n",
       "         ...,\n",
       "         [ 2.4410486 ,  0.90127516,  0.32155848, ...,  1.0094385 ,\n",
       "           0.64623034,  0.8559234 ],\n",
       "         [ 2.4265835 ,  0.89037627,  0.30695826, ...,  1.0435528 ,\n",
       "           0.5997888 ,  0.81485605],\n",
       "         [ 2.397391  ,  0.9396132 ,  0.27008915, ...,  1.0197861 ,\n",
       "           0.6266167 ,  0.83702266]],\n",
       "\n",
       "        [[-0.7122471 ,  0.11438391, -0.38278064, ...,  1.9117907 ,\n",
       "          -1.1966245 , -1.8060119 ],\n",
       "         [-0.690319  ,  0.08650586, -0.39588448, ...,  1.9444695 ,\n",
       "          -1.151432  , -1.7387158 ],\n",
       "         [-0.7052547 ,  0.09722123, -0.43118817, ...,  1.9165137 ,\n",
       "          -1.2020254 , -1.7494527 ],\n",
       "         ...,\n",
       "         [-0.7138582 ,  0.11960095, -0.38271883, ...,  1.9087617 ,\n",
       "          -1.2361103 , -1.7931862 ],\n",
       "         [-0.7233149 ,  0.09268543, -0.39690444, ...,  1.9203069 ,\n",
       "          -1.2362757 , -1.7467881 ],\n",
       "         [-0.7168106 ,  0.093871  , -0.38087052, ...,  1.8864334 ,\n",
       "          -1.2622969 , -1.7770299 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.35045248,  0.6588631 , -1.4716544 , ...,  0.24472359,\n",
       "          -1.7915298 , -0.5988022 ],\n",
       "         [ 0.33840385,  0.65720433, -1.4369732 , ...,  0.2499702 ,\n",
       "          -1.7904766 , -0.67308646],\n",
       "         [ 0.34829366,  0.64648855, -1.4717443 , ...,  0.2557738 ,\n",
       "          -1.7786996 , -0.61343443],\n",
       "         ...,\n",
       "         [ 0.3445264 ,  0.6027417 , -1.4628402 , ...,  0.23897225,\n",
       "          -1.7985466 , -0.63340116],\n",
       "         [ 0.40388227,  0.5923537 , -1.4568517 , ...,  0.27391842,\n",
       "          -1.738383  , -0.6691509 ],\n",
       "         [ 0.33580384,  0.63327736, -1.4491427 , ...,  0.23219478,\n",
       "          -1.8055627 , -0.6611917 ]],\n",
       "\n",
       "        [[ 0.9518429 ,  1.6154572 , -1.831065  , ...,  1.1577702 ,\n",
       "           0.59693944, -0.4189949 ],\n",
       "         [ 0.9556962 ,  1.6443505 , -1.8264143 , ...,  1.1140475 ,\n",
       "           0.58616745, -0.41463947],\n",
       "         [ 0.9130303 ,  1.610981  , -1.8032324 , ...,  1.1603038 ,\n",
       "           0.60051405, -0.45309198],\n",
       "         ...,\n",
       "         [ 0.90531   ,  1.5571332 , -1.8304977 , ...,  1.1800226 ,\n",
       "           0.54860723, -0.4209491 ],\n",
       "         [ 0.93166053,  1.6082045 , -1.8634222 , ...,  1.126869  ,\n",
       "           0.5667187 , -0.45069098],\n",
       "         [ 0.92133737,  1.5829146 , -1.8537939 , ...,  1.1602745 ,\n",
       "           0.5687091 , -0.3878932 ]],\n",
       "\n",
       "        [[-1.5846694 ,  1.3122681 , -0.47875062, ...,  1.3376758 ,\n",
       "          -0.07512677, -1.2620199 ],\n",
       "         [-1.6285197 ,  1.2535746 , -0.514023  , ...,  1.3951383 ,\n",
       "          -0.03134066, -1.2849269 ],\n",
       "         [-1.5811625 ,  1.243865  , -0.54606587, ...,  1.3346119 ,\n",
       "          -0.09262657, -1.2493712 ],\n",
       "         ...,\n",
       "         [-1.5989634 ,  1.2268186 , -0.53734857, ...,  1.351688  ,\n",
       "          -0.04230267, -1.2877486 ],\n",
       "         [-1.5714364 ,  1.2534841 , -0.5054624 , ...,  1.328589  ,\n",
       "          -0.11132002, -1.2489084 ],\n",
       "         [-1.5308585 ,  1.2616144 , -0.52021754, ...,  1.3543949 ,\n",
       "          -0.09979266, -1.2873861 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-1.6119548 ,  0.54628766,  1.201836  , ..., -0.29327363,\n",
       "          -1.1998279 ,  0.0225229 ],\n",
       "         [-1.5633998 ,  0.5450355 ,  1.1768534 , ..., -0.29734707,\n",
       "          -1.2458184 ,  0.04627183],\n",
       "         [-1.6173687 ,  0.60077673,  1.2585069 , ..., -0.36300516,\n",
       "          -1.2009895 ,  0.03173104],\n",
       "         ...,\n",
       "         [-1.6036658 ,  0.5330312 ,  1.2343756 , ..., -0.37009013,\n",
       "          -1.2093778 ,  0.04805827],\n",
       "         [-1.6624489 ,  0.53629506,  1.1781762 , ..., -0.30630577,\n",
       "          -1.2555223 ,  0.05771962],\n",
       "         [-1.6582518 ,  0.54022527,  1.2032756 , ..., -0.30147564,\n",
       "          -1.1604455 ,  0.03208628]],\n",
       "\n",
       "        [[ 0.50902975,  1.1083238 , -0.57628584, ..., -0.8019021 ,\n",
       "           1.4819905 ,  0.14441954],\n",
       "         [ 0.5289286 ,  1.1052868 , -0.47965828, ..., -0.7503155 ,\n",
       "           1.5387925 ,  0.15209177],\n",
       "         [ 0.49533343,  1.0949997 , -0.53384966, ..., -0.75712883,\n",
       "           1.5284586 ,  0.17572613],\n",
       "         ...,\n",
       "         [ 0.47393763,  1.1129456 , -0.4806143 , ..., -0.80557287,\n",
       "           1.5163614 ,  0.12559973],\n",
       "         [ 0.4990558 ,  1.1365054 , -0.54746556, ..., -0.82571775,\n",
       "           1.5250988 ,  0.16129237],\n",
       "         [ 0.4986391 ,  1.082224  , -0.51648635, ..., -0.7825042 ,\n",
       "           1.5096774 ,  0.19468173]],\n",
       "\n",
       "        [[-2.8361366 , -0.13102904, -0.5171407 , ...,  0.2233018 ,\n",
       "          -1.8023864 ,  1.2818701 ],\n",
       "         [-2.7557058 , -0.14697054, -0.50683   , ...,  0.1738944 ,\n",
       "          -1.7889928 ,  1.2515556 ],\n",
       "         [-2.783576  , -0.13309267, -0.49341166, ...,  0.1895434 ,\n",
       "          -1.7985867 ,  1.2040845 ],\n",
       "         ...,\n",
       "         [-2.738843  , -0.11963576, -0.5193441 , ...,  0.22277117,\n",
       "          -1.7763824 ,  1.2122638 ],\n",
       "         [-2.7719655 , -0.10897028, -0.5114472 , ...,  0.21284989,\n",
       "          -1.8205521 ,  1.168254  ],\n",
       "         [-2.8114932 , -0.08894628, -0.48848462, ...,  0.19295943,\n",
       "          -1.8209996 ,  1.188765  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.763788  ,  0.04294449,  0.10684913, ..., -0.9173955 ,\n",
       "          -0.47499192, -1.70396   ],\n",
       "         [ 0.7389526 ,  0.08989209,  0.11544214, ..., -0.9254991 ,\n",
       "          -0.42664862, -1.719191  ],\n",
       "         [ 0.78962517,  0.07938874,  0.12263872, ..., -0.8786428 ,\n",
       "          -0.4485823 , -1.7085764 ],\n",
       "         ...,\n",
       "         [ 0.77367425,  0.04034323,  0.11848404, ..., -0.91419685,\n",
       "          -0.44583488, -1.7081821 ],\n",
       "         [ 0.7693149 ,  0.03882402,  0.07352938, ..., -0.9448073 ,\n",
       "          -0.4981377 , -1.6238333 ],\n",
       "         [ 0.7502209 ,  0.03046215,  0.11784758, ..., -0.9241922 ,\n",
       "          -0.48381922, -1.6764017 ]],\n",
       "\n",
       "        [[-1.2729876 ,  2.2666368 ,  0.21756929, ..., -0.15414143,\n",
       "           0.5417136 ,  1.0718205 ],\n",
       "         [-1.2582983 ,  2.2465985 ,  0.20469105, ..., -0.1824359 ,\n",
       "           0.56310326,  1.0783907 ],\n",
       "         [-1.3028104 ,  2.2691836 ,  0.14505726, ..., -0.19079518,\n",
       "           0.568012  ,  1.0830806 ],\n",
       "         ...,\n",
       "         [-1.268011  ,  2.2784657 ,  0.23945725, ..., -0.19663706,\n",
       "           0.5914648 ,  1.1104493 ],\n",
       "         [-1.3006971 ,  2.302459  ,  0.23766363, ..., -0.19096467,\n",
       "           0.5269048 ,  1.1017892 ],\n",
       "         [-1.2862151 ,  2.2569275 ,  0.2586733 , ..., -0.20722057,\n",
       "           0.5123708 ,  1.1230092 ]],\n",
       "\n",
       "        [[-0.6659012 , -0.6967529 , -0.6528518 , ...,  0.02397871,\n",
       "           0.27554438, -0.65773034],\n",
       "         [-0.6515174 , -0.6481135 , -0.69204634, ...,  0.11506748,\n",
       "           0.30865481, -0.6360637 ],\n",
       "         [-0.68245536, -0.7190109 , -0.682291  , ...,  0.07499588,\n",
       "           0.3459111 , -0.6199237 ],\n",
       "         ...,\n",
       "         [-0.65988487, -0.7149191 , -0.6651783 , ...,  0.0215261 ,\n",
       "           0.31886035, -0.6654726 ],\n",
       "         [-0.65603524, -0.7239933 , -0.68078214, ...,  0.05426764,\n",
       "           0.3111465 , -0.64331967],\n",
       "         [-0.6859779 , -0.6986027 , -0.68853986, ...,  0.07721102,\n",
       "           0.26163048, -0.6407702 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-4.1890401e-01, -1.1014183e+00,  4.0967897e-01, ...,\n",
       "           1.6173625e+00, -2.3221168e-01, -3.4016013e-02],\n",
       "         [-4.2636129e-01, -1.0903103e+00,  3.6791039e-01, ...,\n",
       "           1.5923120e+00, -1.7859289e-01, -3.2140255e-02],\n",
       "         [-4.0745109e-01, -1.1383145e+00,  3.4406430e-01, ...,\n",
       "           1.6181037e+00, -1.9734958e-01,  1.5688717e-02],\n",
       "         ...,\n",
       "         [-4.2748415e-01, -1.0963331e+00,  3.8191333e-01, ...,\n",
       "           1.5895724e+00, -2.0542383e-01,  8.8416338e-03],\n",
       "         [-4.3731257e-01, -1.0953121e+00,  4.0694302e-01, ...,\n",
       "           1.6323483e+00, -2.1076936e-01,  1.3373435e-02],\n",
       "         [-4.1987213e-01, -1.0829185e+00,  3.7973979e-01, ...,\n",
       "           1.6108282e+00, -2.0125896e-01, -1.1440694e-02]],\n",
       "\n",
       "        [[ 1.7997432e-01, -2.6965618e-01, -1.1461933e+00, ...,\n",
       "           5.0977325e-01, -1.0602888e+00, -1.6604769e-01],\n",
       "         [ 1.9639194e-01, -2.4949944e-01, -1.1456020e+00, ...,\n",
       "           4.6926516e-01, -1.0219867e+00, -1.2155151e-01],\n",
       "         [ 1.9273865e-01, -2.5287491e-01, -1.1189719e+00, ...,\n",
       "           4.6358985e-01, -1.0495138e+00, -1.7287081e-01],\n",
       "         ...,\n",
       "         [ 1.4622009e-01, -3.0397427e-01, -1.1548274e+00, ...,\n",
       "           4.9949756e-01, -1.0615724e+00, -1.5389085e-01],\n",
       "         [ 1.9001079e-01, -2.7770787e-01, -1.1179276e+00, ...,\n",
       "           5.1571560e-01, -1.0715547e+00, -1.4907998e-01],\n",
       "         [ 1.3358784e-01, -2.6002240e-01, -1.1487038e+00, ...,\n",
       "           4.7384590e-01, -1.0539104e+00, -1.5347868e-01]],\n",
       "\n",
       "        [[-3.1675747e-01,  1.3654910e+00, -9.7229242e-01, ...,\n",
       "           1.2946150e+00,  7.8321415e-01,  8.1816339e-01],\n",
       "         [-3.0439389e-01,  1.3856146e+00, -9.4970655e-01, ...,\n",
       "           1.2861751e+00,  7.6511639e-01,  8.5718954e-01],\n",
       "         [-3.0174926e-01,  1.3947797e+00, -9.6635759e-01, ...,\n",
       "           1.2552722e+00,  8.0660594e-01,  8.2890916e-01],\n",
       "         ...,\n",
       "         [-2.5483775e-01,  1.3922849e+00, -9.7937226e-01, ...,\n",
       "           1.2859098e+00,  7.7042902e-01,  8.3487213e-01],\n",
       "         [-3.0089447e-01,  1.3846639e+00, -9.4998705e-01, ...,\n",
       "           1.2819490e+00,  7.4987066e-01,  8.4780061e-01],\n",
       "         [-2.8205016e-01,  1.4049990e+00, -9.8695314e-01, ...,\n",
       "           1.2635062e+00,  7.7483571e-01,  8.2852077e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.6343117e-02,  1.3995439e-01,  6.4837188e-01, ...,\n",
       "          -2.4877877e+00, -8.9119107e-01, -3.0355275e+00],\n",
       "         [ 8.4077716e-03,  1.3980946e-01,  6.7238426e-01, ...,\n",
       "          -2.4680862e+00, -9.1032749e-01, -2.9592938e+00],\n",
       "         [-8.9717507e-03,  1.8160209e-01,  6.5470946e-01, ...,\n",
       "          -2.4675937e+00, -8.8107204e-01, -3.0010824e+00],\n",
       "         ...,\n",
       "         [-3.9618850e-02,  1.7339915e-01,  6.4210397e-01, ...,\n",
       "          -2.4512877e+00, -8.8709855e-01, -2.9836898e+00],\n",
       "         [-1.1531413e-03,  1.7611989e-01,  6.6101933e-01, ...,\n",
       "          -2.4809756e+00, -9.1596049e-01, -3.0079043e+00],\n",
       "         [-2.5073290e-03,  1.8060216e-01,  6.4751637e-01, ...,\n",
       "          -2.4934418e+00, -8.9488101e-01, -3.0023162e+00]],\n",
       "\n",
       "        [[ 7.2287118e-01,  3.3581076e+00,  5.2911198e-01, ...,\n",
       "          -3.6719635e-01,  2.1732454e+00, -5.2632284e-01],\n",
       "         [ 7.1737128e-01,  3.3661342e+00,  4.7968799e-01, ...,\n",
       "          -3.6070299e-01,  2.1682076e+00, -5.2041334e-01],\n",
       "         [ 7.3810911e-01,  3.3588161e+00,  5.3001553e-01, ...,\n",
       "          -2.9714578e-01,  2.1524620e+00, -5.1279891e-01],\n",
       "         ...,\n",
       "         [ 7.4031103e-01,  3.3822465e+00,  5.2928615e-01, ...,\n",
       "          -3.2147413e-01,  2.1722846e+00, -5.0537914e-01],\n",
       "         [ 7.3369980e-01,  3.3865607e+00,  5.7626677e-01, ...,\n",
       "          -3.5720533e-01,  2.1681895e+00, -5.4518104e-01],\n",
       "         [ 7.1232545e-01,  3.3665280e+00,  5.1927251e-01, ...,\n",
       "          -3.4558666e-01,  2.1509783e+00, -5.1859778e-01]],\n",
       "\n",
       "        [[ 1.2361797e+00,  2.1091745e+00,  3.4167156e-01, ...,\n",
       "          -6.6330850e-01, -6.9018662e-01,  6.2146926e-01],\n",
       "         [ 1.2228928e+00,  2.1360512e+00,  3.6559591e-01, ...,\n",
       "          -6.8856108e-01, -6.8163455e-01,  6.2549096e-01],\n",
       "         [ 1.2707398e+00,  2.1009862e+00,  3.6599234e-01, ...,\n",
       "          -6.8399936e-01, -6.8943441e-01,  6.1903179e-01],\n",
       "         ...,\n",
       "         [ 1.2318394e+00,  2.1038501e+00,  3.7325096e-01, ...,\n",
       "          -7.1781105e-01, -7.1646726e-01,  6.5623450e-01],\n",
       "         [ 1.2547070e+00,  2.1473210e+00,  3.5810784e-01, ...,\n",
       "          -6.8406367e-01, -7.0477259e-01,  5.8797109e-01],\n",
       "         [ 1.2118802e+00,  2.1459365e+00,  3.0987722e-01, ...,\n",
       "          -7.2149205e-01, -6.7626500e-01,  6.5794742e-01]]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 2.6001346 ,  0.5321752 ,  0.9272466 , ..., -0.48109463,\n",
       "           0.7905108 , -1.1552734 ],\n",
       "         [ 2.6255238 ,  0.5151496 ,  0.96144795, ..., -0.4734387 ,\n",
       "           0.7961241 , -1.1712704 ],\n",
       "         [ 2.5937805 ,  0.46844956,  0.9504924 , ..., -0.5435037 ,\n",
       "           0.77369046, -1.1438129 ],\n",
       "         ...,\n",
       "         [ 2.586826  ,  0.49913847,  0.91614497, ..., -0.5152888 ,\n",
       "           0.7863932 , -1.1610473 ],\n",
       "         [ 2.6105952 ,  0.5377188 ,  0.9522685 , ..., -0.50563186,\n",
       "           0.76256394, -1.1546141 ],\n",
       "         [ 2.5815117 ,  0.51946586,  0.9538404 , ..., -0.5048839 ,\n",
       "           0.8163989 , -1.1842628 ]],\n",
       "\n",
       "        [[-1.6747614 , -1.8327441 ,  1.2555237 , ...,  1.4001038 ,\n",
       "          -0.6436602 ,  1.2338724 ],\n",
       "         [-1.6883919 , -1.8122094 ,  1.2549542 , ...,  1.4147724 ,\n",
       "          -0.6428802 ,  1.256393  ],\n",
       "         [-1.6821653 , -1.8295236 ,  1.2481041 , ...,  1.4478137 ,\n",
       "          -0.6111963 ,  1.2326403 ],\n",
       "         ...,\n",
       "         [-1.6764886 , -1.8160958 ,  1.2658339 , ...,  1.4257189 ,\n",
       "          -0.6213292 ,  1.2721272 ],\n",
       "         [-1.6976116 , -1.8153222 ,  1.2268169 , ...,  1.4312263 ,\n",
       "          -0.628979  ,  1.2427993 ],\n",
       "         [-1.6459155 , -1.8368739 ,  1.2418045 , ...,  1.3885661 ,\n",
       "          -0.64301455,  1.2709044 ]],\n",
       "\n",
       "        [[-1.7464916 , -2.6944964 , -1.1044368 , ...,  1.186629  ,\n",
       "          -0.22038323,  0.09201765],\n",
       "         [-1.7770746 , -2.6601872 , -1.1010683 , ...,  1.18295   ,\n",
       "          -0.2314902 ,  0.12950313],\n",
       "         [-1.7462015 , -2.6831129 , -1.1333232 , ...,  1.1733148 ,\n",
       "          -0.22922671,  0.0830248 ],\n",
       "         ...,\n",
       "         [-1.7342423 , -2.6911173 , -1.1033052 , ...,  1.2005793 ,\n",
       "          -0.21723372,  0.06196982],\n",
       "         [-1.7413837 , -2.6496394 , -1.1212847 , ...,  1.1726459 ,\n",
       "          -0.28782398,  0.07094586],\n",
       "         [-1.7305521 , -2.6600056 , -1.0880802 , ...,  1.1827466 ,\n",
       "          -0.2275896 ,  0.09839404]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.19406807, -0.55916524, -0.04290062, ..., -0.3503673 ,\n",
       "           0.8592237 , -1.5557581 ],\n",
       "         [-0.20895907, -0.59362525, -0.05839989, ..., -0.3821056 ,\n",
       "           0.85928905, -1.5637532 ],\n",
       "         [-0.21607655, -0.6266376 , -0.04486144, ..., -0.36404425,\n",
       "           0.8923426 , -1.5629781 ],\n",
       "         ...,\n",
       "         [-0.20832878, -0.57209736, -0.05691466, ..., -0.35947818,\n",
       "           0.8763086 , -1.5490506 ],\n",
       "         [-0.19863835, -0.5379308 , -0.0496403 , ..., -0.32972953,\n",
       "           0.86230963, -1.5673454 ],\n",
       "         [-0.21932292, -0.57382405, -0.04554409, ..., -0.39369562,\n",
       "           0.87116235, -1.5421909 ]],\n",
       "\n",
       "        [[-0.4223649 , -1.7358458 , -1.7763674 , ...,  1.2310739 ,\n",
       "          -0.9879569 , -0.29551268],\n",
       "         [-0.44109744, -1.7239947 , -1.7924824 , ...,  1.1900938 ,\n",
       "          -0.9905908 , -0.2377249 ],\n",
       "         [-0.45888257, -1.7337196 , -1.7963009 , ...,  1.2428864 ,\n",
       "          -0.96402454, -0.28549087],\n",
       "         ...,\n",
       "         [-0.43790597, -1.7742476 , -1.772624  , ...,  1.2034473 ,\n",
       "          -0.9240603 , -0.28637052],\n",
       "         [-0.4268138 , -1.7394508 , -1.7895428 , ...,  1.2074695 ,\n",
       "          -0.96922004, -0.28961802],\n",
       "         [-0.4388627 , -1.765249  , -1.7676322 , ...,  1.2585034 ,\n",
       "          -0.9659462 , -0.25142908]],\n",
       "\n",
       "        [[ 0.42986217,  1.2945852 , -1.2011468 , ...,  0.33690557,\n",
       "           0.86674714, -1.1240314 ],\n",
       "         [ 0.42649296,  1.3022203 , -1.2023458 , ...,  0.40624908,\n",
       "           0.8831881 , -1.0958194 ],\n",
       "         [ 0.43224788,  1.2762058 , -1.1839886 , ...,  0.384041  ,\n",
       "           0.8935979 , -1.125993  ],\n",
       "         ...,\n",
       "         [ 0.37044442,  1.2775421 , -1.1814859 , ...,  0.3581833 ,\n",
       "           0.9002085 , -1.1410427 ],\n",
       "         [ 0.40571693,  1.298856  , -1.2224212 , ...,  0.3687532 ,\n",
       "           0.87309074, -1.1367753 ],\n",
       "         [ 0.41818318,  1.2618849 , -1.2050188 , ...,  0.35690615,\n",
       "           0.8459377 , -1.1234059 ]]]], dtype=float32)>), (<tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.49246052, -0.38826114, -1.1750504 , ...,  0.55793726,\n",
       "           0.8153955 ,  0.36669362],\n",
       "         [ 0.5080019 , -0.40245128, -1.2006135 , ...,  0.5408921 ,\n",
       "           0.7837348 ,  0.31284732],\n",
       "         [ 0.48703358, -0.39209634, -1.1938391 , ...,  0.5270095 ,\n",
       "           0.78595716,  0.3330049 ],\n",
       "         ...,\n",
       "         [ 0.4819975 , -0.36521536, -1.1566975 , ...,  0.5329039 ,\n",
       "           0.8191807 ,  0.34651816],\n",
       "         [ 0.4803108 , -0.4157047 , -1.1532676 , ...,  0.5120888 ,\n",
       "           0.79338014,  0.37085116],\n",
       "         [ 0.4784036 , -0.3885609 , -1.1359185 , ...,  0.5284368 ,\n",
       "           0.8056821 ,  0.34238696]],\n",
       "\n",
       "        [[ 1.1425152 , -1.2914941 ,  0.1116842 , ...,  0.9652991 ,\n",
       "           0.05973321, -0.50264907],\n",
       "         [ 1.127376  , -1.2851276 ,  0.15259129, ...,  0.9581033 ,\n",
       "           0.11109501, -0.5089474 ],\n",
       "         [ 1.161284  , -1.27773   ,  0.10270447, ...,  1.0058129 ,\n",
       "           0.0946179 , -0.520797  ],\n",
       "         ...,\n",
       "         [ 1.1620245 , -1.2325213 ,  0.13344485, ...,  0.9192243 ,\n",
       "           0.13090214, -0.5197741 ],\n",
       "         [ 1.1439198 , -1.2854486 ,  0.15737492, ...,  0.96997595,\n",
       "           0.07468775, -0.5504164 ],\n",
       "         [ 1.1621785 , -1.2931819 ,  0.11870432, ...,  0.97635615,\n",
       "           0.11118424, -0.55627304]],\n",
       "\n",
       "        [[ 1.2353606 , -0.5901303 , -0.8561478 , ...,  0.28893033,\n",
       "           0.66453445,  2.4096792 ],\n",
       "         [ 1.2992421 , -0.639473  , -0.8558562 , ...,  0.24106784,\n",
       "           0.69770855,  2.384924  ],\n",
       "         [ 1.3042936 , -0.6432341 , -0.8916139 , ...,  0.24644557,\n",
       "           0.7249379 ,  2.3852851 ],\n",
       "         ...,\n",
       "         [ 1.3011621 , -0.64774907, -0.89927065, ...,  0.25660366,\n",
       "           0.65752536,  2.422538  ],\n",
       "         [ 1.3130058 , -0.6266504 , -0.87191963, ...,  0.25783983,\n",
       "           0.6748879 ,  2.3857505 ],\n",
       "         [ 1.3057399 , -0.65978837, -0.8987934 , ...,  0.28074735,\n",
       "           0.6455975 ,  2.39601   ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.29870528,  2.19386   , -0.32437676, ..., -0.00972891,\n",
       "           0.7605679 , -0.69750476],\n",
       "         [ 0.30835298,  2.210802  , -0.27561152, ...,  0.01623815,\n",
       "           0.7096815 , -0.6174042 ],\n",
       "         [ 0.2876788 ,  2.1741276 , -0.2963853 , ...,  0.00334918,\n",
       "           0.68300486, -0.6473217 ],\n",
       "         ...,\n",
       "         [ 0.30867943,  2.1809416 , -0.29114017, ...,  0.01365417,\n",
       "           0.71529746, -0.6228527 ],\n",
       "         [ 0.30109942,  2.1756992 , -0.30019602, ...,  0.00980613,\n",
       "           0.7164321 , -0.62824845],\n",
       "         [ 0.28123453,  2.194991  , -0.28417337, ...,  0.02166507,\n",
       "           0.75024366, -0.670398  ]],\n",
       "\n",
       "        [[-0.36649072,  1.0595493 , -0.7461356 , ...,  0.5462837 ,\n",
       "           0.53116167,  0.70053124],\n",
       "         [-0.38982737,  1.0861775 , -0.78000474, ...,  0.51400596,\n",
       "           0.47435683,  0.68983126],\n",
       "         [-0.37518853,  1.0641427 , -0.7390545 , ...,  0.53254557,\n",
       "           0.5033939 ,  0.67649126],\n",
       "         ...,\n",
       "         [-0.32364112,  1.1109211 , -0.7583157 , ...,  0.5707038 ,\n",
       "           0.4999568 ,  0.68776363],\n",
       "         [-0.34341317,  1.1163895 , -0.73845196, ...,  0.56847435,\n",
       "           0.52251315,  0.6504311 ],\n",
       "         [-0.31894583,  1.0955303 , -0.75382173, ...,  0.57096493,\n",
       "           0.5333107 ,  0.7035544 ]],\n",
       "\n",
       "        [[ 0.31008798, -1.5074086 , -0.29200214, ..., -0.90778303,\n",
       "          -0.4567182 , -1.0578831 ],\n",
       "         [ 0.31076735, -1.4480224 , -0.29701865, ..., -0.87668943,\n",
       "          -0.4714324 , -1.0642651 ],\n",
       "         [ 0.34468436, -1.4776058 , -0.3325128 , ..., -0.90430117,\n",
       "          -0.47603527, -1.0805912 ],\n",
       "         ...,\n",
       "         [ 0.28446668, -1.4477229 , -0.31271976, ..., -0.8781997 ,\n",
       "          -0.50059444, -1.0557383 ],\n",
       "         [ 0.28382003, -1.4650763 , -0.32792932, ..., -0.863972  ,\n",
       "          -0.43765682, -1.0718477 ],\n",
       "         [ 0.28852004, -1.4597135 , -0.37660545, ..., -0.83618236,\n",
       "          -0.49841642, -1.048259  ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-6.05669975e-01,  3.40469450e-01,  6.38135076e-02, ...,\n",
       "           1.30340850e+00,  8.99179399e-01,  1.08425510e+00],\n",
       "         [-6.43606603e-01,  3.12552392e-01,  8.07466209e-02, ...,\n",
       "           1.34792721e+00,  8.80839944e-01,  1.09487140e+00],\n",
       "         [-6.08449936e-01,  3.35319251e-01,  5.65208495e-02, ...,\n",
       "           1.32311702e+00,  9.17340934e-01,  1.10960627e+00],\n",
       "         ...,\n",
       "         [-6.31016016e-01,  3.47562790e-01,  7.49911964e-02, ...,\n",
       "           1.26878977e+00,  9.30259347e-01,  1.11926317e+00],\n",
       "         [-6.48365021e-01,  3.60168219e-01,  7.00883418e-02, ...,\n",
       "           1.27927685e+00,  9.55738068e-01,  1.09866619e+00],\n",
       "         [-6.37213349e-01,  3.55634391e-01,  9.60956812e-02, ...,\n",
       "           1.29875243e+00,  9.06523347e-01,  1.07185507e+00]],\n",
       "\n",
       "        [[ 1.26710844e+00,  1.37423301e+00, -7.72866726e-01, ...,\n",
       "          -1.67563498e-01,  2.79715359e-01, -8.98012459e-01],\n",
       "         [ 1.25098705e+00,  1.35476685e+00, -7.34737098e-01, ...,\n",
       "          -1.76732481e-01,  3.92301202e-01, -9.20096338e-01],\n",
       "         [ 1.24026072e+00,  1.36485147e+00, -7.38475084e-01, ...,\n",
       "          -1.56854808e-01,  3.49470884e-01, -9.12808955e-01],\n",
       "         ...,\n",
       "         [ 1.31323886e+00,  1.36801720e+00, -7.55174041e-01, ...,\n",
       "          -1.41724288e-01,  4.23884779e-01, -8.85557771e-01],\n",
       "         [ 1.27434921e+00,  1.34850347e+00, -7.46215522e-01, ...,\n",
       "          -1.57144845e-01,  4.35978711e-01, -9.43884373e-01],\n",
       "         [ 1.29534006e+00,  1.37947595e+00, -7.59263158e-01, ...,\n",
       "          -1.34215236e-01,  3.94764304e-01, -8.92612517e-01]],\n",
       "\n",
       "        [[-6.70822263e-02,  1.73879313e+00,  1.13638377e+00, ...,\n",
       "           1.97376657e+00, -2.06536442e-01,  2.21105933e-01],\n",
       "         [-9.55097079e-02,  1.75743246e+00,  1.11509514e+00, ...,\n",
       "           1.96200526e+00, -2.65453726e-01,  2.19893903e-01],\n",
       "         [-7.46783614e-02,  1.76255667e+00,  1.14740658e+00, ...,\n",
       "           2.01788473e+00, -1.90141797e-01,  2.52052158e-01],\n",
       "         ...,\n",
       "         [-6.64877594e-02,  1.76457322e+00,  1.19210458e+00, ...,\n",
       "           2.01685476e+00, -2.19401658e-01,  2.27753103e-01],\n",
       "         [-5.56087494e-02,  1.77873385e+00,  1.20006061e+00, ...,\n",
       "           1.98989046e+00, -2.09489584e-01,  2.05823362e-01],\n",
       "         [-6.54920638e-02,  1.73254418e+00,  1.19847000e+00, ...,\n",
       "           1.98232543e+00, -1.80464983e-01,  2.32560843e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.66051465e-01, -1.33473426e-02, -1.29862499e+00, ...,\n",
       "          -1.92780703e-01,  2.48465419e-01,  9.49800909e-02],\n",
       "         [-3.11214089e-01, -1.72789544e-02, -1.31180036e+00, ...,\n",
       "          -2.13771820e-01,  2.33316541e-01,  7.36556649e-02],\n",
       "         [-3.38383198e-01,  3.53454426e-02, -1.28283715e+00, ...,\n",
       "          -1.08944595e-01,  2.47872829e-01,  4.54830527e-02],\n",
       "         ...,\n",
       "         [-3.12565327e-01,  2.28184164e-02, -1.28931439e+00, ...,\n",
       "          -1.71577871e-01,  2.53264546e-01,  8.17778111e-02],\n",
       "         [-3.11031252e-01,  2.47694477e-02, -1.27706015e+00, ...,\n",
       "          -1.45433724e-01,  2.70227551e-01,  1.09899551e-01],\n",
       "         [-3.15851927e-01,  4.77763861e-02, -1.28215861e+00, ...,\n",
       "          -1.40392542e-01,  2.02849269e-01,  8.29707086e-02]],\n",
       "\n",
       "        [[-1.37190595e-02, -5.38381994e-01,  5.14007568e-01, ...,\n",
       "           4.84637648e-01,  9.31870699e-01, -1.96058989e+00],\n",
       "         [-3.66700739e-02, -5.25049150e-01,  4.96962070e-01, ...,\n",
       "           4.17525887e-01,  9.40859377e-01, -1.95113122e+00],\n",
       "         [-7.77337700e-04, -5.32421589e-01,  5.45327902e-01, ...,\n",
       "           4.60241169e-01,  9.01769161e-01, -1.93670762e+00],\n",
       "         ...,\n",
       "         [-2.47186795e-02, -5.51605463e-01,  5.45964479e-01, ...,\n",
       "           4.40290511e-01,  8.89087677e-01, -1.94348669e+00],\n",
       "         [-3.35809849e-02, -5.15586138e-01,  5.65945029e-01, ...,\n",
       "           4.98951197e-01,  9.07546163e-01, -1.94794667e+00],\n",
       "         [-2.24961117e-02, -5.35856724e-01,  5.09407282e-01, ...,\n",
       "           4.75540221e-01,  9.03657436e-01, -1.94019556e+00]],\n",
       "\n",
       "        [[-1.47001445e+00,  3.32834572e-01, -1.06807852e+00, ...,\n",
       "           9.16057110e-01,  1.54276896e+00, -1.08220667e-01],\n",
       "         [-1.52904582e+00,  3.03004235e-01, -1.07165956e+00, ...,\n",
       "           9.12847877e-01,  1.53821754e+00, -7.97472596e-02],\n",
       "         [-1.48207784e+00,  3.19202751e-01, -1.08020520e+00, ...,\n",
       "           9.16275561e-01,  1.49772823e+00, -1.15953207e-01],\n",
       "         ...,\n",
       "         [-1.50854993e+00,  2.70175755e-01, -1.07931530e+00, ...,\n",
       "           8.85305643e-01,  1.50266981e+00, -1.21579766e-01],\n",
       "         [-1.50792694e+00,  2.78214484e-01, -1.09758019e+00, ...,\n",
       "           8.85749936e-01,  1.46314859e+00, -1.39372587e-01],\n",
       "         [-1.46844661e+00,  2.69111216e-01, -1.04863954e+00, ...,\n",
       "           8.93419504e-01,  1.49861336e+00, -8.63395035e-02]]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-0.36303207,  0.39212346, -0.86011446, ...,  0.59961873,\n",
       "          -1.1933906 , -2.0295434 ],\n",
       "         [-0.36624622,  0.34783566, -0.87875956, ...,  0.59012485,\n",
       "          -1.2025237 , -2.0040736 ],\n",
       "         [-0.39972073,  0.3531425 , -0.86753416, ...,  0.5718336 ,\n",
       "          -1.2042422 , -2.0283175 ],\n",
       "         ...,\n",
       "         [-0.39757955,  0.37506485, -0.87874305, ...,  0.62361777,\n",
       "          -1.1931584 , -2.0188413 ],\n",
       "         [-0.3906381 ,  0.3648765 , -0.86618656, ...,  0.57808876,\n",
       "          -1.1830927 , -2.0369518 ],\n",
       "         [-0.38876033,  0.39579523, -0.87035877, ...,  0.59478307,\n",
       "          -1.2180166 , -2.0400288 ]],\n",
       "\n",
       "        [[-0.16973273,  0.51057714,  1.3616049 , ..., -0.5076691 ,\n",
       "          -0.10825455,  1.3902972 ],\n",
       "         [-0.193281  ,  0.46534848,  1.3446337 , ..., -0.5636925 ,\n",
       "          -0.10635602,  1.40729   ],\n",
       "         [-0.18586478,  0.5076879 ,  1.3438189 , ..., -0.5370067 ,\n",
       "          -0.06928688,  1.3995476 ],\n",
       "         ...,\n",
       "         [-0.15930462,  0.51559997,  1.3593615 , ..., -0.5484133 ,\n",
       "          -0.09165531,  1.4223022 ],\n",
       "         [-0.17251995,  0.47718525,  1.3877904 , ..., -0.5164758 ,\n",
       "          -0.06407136,  1.3935789 ],\n",
       "         [-0.17547221,  0.50988543,  1.419171  , ..., -0.54372203,\n",
       "          -0.10641301,  1.3700371 ]],\n",
       "\n",
       "        [[ 0.4143517 , -0.94760984,  0.1574539 , ..., -0.60905397,\n",
       "           0.6586453 ,  0.45247695],\n",
       "         [ 0.43030524, -0.9368844 ,  0.1340156 , ..., -0.6566396 ,\n",
       "           0.6625938 ,  0.4849271 ],\n",
       "         [ 0.41710353, -0.95164025,  0.13415265, ..., -0.6142523 ,\n",
       "           0.6549282 ,  0.44056016],\n",
       "         ...,\n",
       "         [ 0.43733853, -0.9738677 ,  0.13740754, ..., -0.6105237 ,\n",
       "           0.64563525,  0.4528006 ],\n",
       "         [ 0.41304368, -0.9371556 ,  0.13993584, ..., -0.5881793 ,\n",
       "           0.6537602 ,  0.46772328],\n",
       "         [ 0.47784066, -0.9296944 ,  0.15935202, ..., -0.5726268 ,\n",
       "           0.63975346,  0.43547657]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.8482944 , -0.32901832, -0.36908114, ...,  1.8381102 ,\n",
       "          -0.26371396, -0.14017388],\n",
       "         [ 1.844189  , -0.28992447, -0.42011672, ...,  1.8245189 ,\n",
       "          -0.23587997, -0.14566281],\n",
       "         [ 1.87286   , -0.30942094, -0.37472603, ...,  1.8584226 ,\n",
       "          -0.2131995 , -0.15615451],\n",
       "         ...,\n",
       "         [ 1.8726996 , -0.32707435, -0.39630336, ...,  1.863893  ,\n",
       "          -0.27033496, -0.15193468],\n",
       "         [ 1.8371835 , -0.29881096, -0.38455772, ...,  1.8160001 ,\n",
       "          -0.2513296 , -0.15138128],\n",
       "         [ 1.8562814 , -0.3367474 , -0.36705548, ...,  1.8655853 ,\n",
       "          -0.22709517, -0.14722803]],\n",
       "\n",
       "        [[ 2.3813086 ,  0.43165857,  2.2748451 , ...,  0.4895961 ,\n",
       "           0.6612492 ,  0.9265969 ],\n",
       "         [ 2.3686287 ,  0.47455248,  2.2665877 , ...,  0.47666895,\n",
       "           0.6433659 ,  0.8990289 ],\n",
       "         [ 2.3791137 ,  0.42837983,  2.2567997 , ...,  0.500407  ,\n",
       "           0.6351137 ,  0.88959354],\n",
       "         ...,\n",
       "         [ 2.3968735 ,  0.44196323,  2.258033  , ...,  0.4650052 ,\n",
       "           0.6268729 ,  0.91060555],\n",
       "         [ 2.3787727 ,  0.47034428,  2.278904  , ...,  0.47350797,\n",
       "           0.5915118 ,  0.9095345 ],\n",
       "         [ 2.383837  ,  0.44822335,  2.2577515 , ...,  0.49738875,\n",
       "           0.5911841 ,  0.89115226]],\n",
       "\n",
       "        [[ 0.29864064,  0.90916896, -0.12569827, ...,  0.6435766 ,\n",
       "          -0.46247548,  0.36546004],\n",
       "         [ 0.29598713,  0.86610544, -0.13682199, ...,  0.66448414,\n",
       "          -0.47736335,  0.3380454 ],\n",
       "         [ 0.27020445,  0.9081793 , -0.09861797, ...,  0.66493213,\n",
       "          -0.49276948,  0.32256055],\n",
       "         ...,\n",
       "         [ 0.28126585,  0.8604304 , -0.12439358, ...,  0.6470262 ,\n",
       "          -0.5174018 ,  0.36426884],\n",
       "         [ 0.31200162,  0.8657363 , -0.09358162, ...,  0.6529513 ,\n",
       "          -0.46343505,  0.36384702],\n",
       "         [ 0.30623928,  0.85343707, -0.14355779, ...,  0.64854527,\n",
       "          -0.46107298,  0.32746565]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 1.1266828 ,  0.06490684,  0.18206406, ..., -0.21361113,\n",
       "          -1.3947291 , -0.08994471],\n",
       "         [ 1.1689179 ,  0.08664149,  0.17575681, ..., -0.21374488,\n",
       "          -1.3942103 , -0.05559537],\n",
       "         [ 1.1386594 ,  0.08929914,  0.177374  , ..., -0.21520348,\n",
       "          -1.393709  , -0.06424706],\n",
       "         ...,\n",
       "         [ 1.1559128 ,  0.11012024,  0.1615957 , ..., -0.19553849,\n",
       "          -1.3545237 , -0.09860572],\n",
       "         [ 1.1388392 ,  0.07199329,  0.14527738, ..., -0.18865108,\n",
       "          -1.3939998 , -0.10742576],\n",
       "         [ 1.1291081 ,  0.09044361,  0.17428267, ..., -0.18152332,\n",
       "          -1.3461175 , -0.09819575]],\n",
       "\n",
       "        [[ 0.8444663 , -0.9148474 ,  0.00446352, ..., -0.7141682 ,\n",
       "          -0.03999233,  0.08695656],\n",
       "         [ 0.83586705, -0.96473694,  0.02449124, ..., -0.6983979 ,\n",
       "          -0.06864241,  0.0177604 ],\n",
       "         [ 0.8634697 , -0.9226026 ,  0.02498446, ..., -0.7474227 ,\n",
       "          -0.05665943,  0.0621987 ],\n",
       "         ...,\n",
       "         [ 0.8625289 , -0.93068004,  0.04103824, ..., -0.7051041 ,\n",
       "          -0.04380697,  0.04298371],\n",
       "         [ 0.8487421 , -0.89903116,  0.03387594, ..., -0.6971743 ,\n",
       "          -0.0551348 ,  0.06289816],\n",
       "         [ 0.84605086, -0.92205656,  0.02011888, ..., -0.7164607 ,\n",
       "          -0.07315773,  0.03664428]],\n",
       "\n",
       "        [[-0.45843643,  0.72545004, -0.15553916, ...,  1.408282  ,\n",
       "          -0.45499074,  1.0296329 ],\n",
       "         [-0.42476475,  0.7432934 , -0.17906064, ...,  1.4487832 ,\n",
       "          -0.4313933 ,  1.0731745 ],\n",
       "         [-0.45043695,  0.7221427 , -0.20938247, ...,  1.4286317 ,\n",
       "          -0.48924053,  1.0619135 ],\n",
       "         ...,\n",
       "         [-0.4635719 ,  0.73784506, -0.17071173, ...,  1.4387271 ,\n",
       "          -0.4594437 ,  1.0439796 ],\n",
       "         [-0.40631092,  0.7205879 , -0.15139106, ...,  1.4165032 ,\n",
       "          -0.47952378,  1.0705643 ],\n",
       "         [-0.47433096,  0.71550196, -0.19017541, ...,  1.4085592 ,\n",
       "          -0.44194278,  1.0411677 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.8485529 ,  0.65067935, -1.5638434 , ..., -0.17342949,\n",
       "           2.45619   ,  0.21211222],\n",
       "         [-0.8362895 ,  0.66157126, -1.5354363 , ..., -0.16324282,\n",
       "           2.4557233 ,  0.18039852],\n",
       "         [-0.8402577 ,  0.6805204 , -1.5659969 , ..., -0.20172048,\n",
       "           2.46607   ,  0.18195048],\n",
       "         ...,\n",
       "         [-0.84705997,  0.66175526, -1.5627615 , ..., -0.1548692 ,\n",
       "           2.465865  ,  0.1644502 ],\n",
       "         [-0.8667799 ,  0.63948613, -1.5761806 , ..., -0.17080438,\n",
       "           2.4830513 ,  0.16192064],\n",
       "         [-0.8507278 ,  0.6573539 , -1.5965532 , ..., -0.18370253,\n",
       "           2.4448118 ,  0.15587342]],\n",
       "\n",
       "        [[-0.59262323,  0.30342782, -1.2699621 , ..., -1.0242184 ,\n",
       "          -0.29668093,  0.83705217],\n",
       "         [-0.5340018 ,  0.3071071 , -1.2445079 , ..., -1.0475271 ,\n",
       "          -0.31140295,  0.8102739 ],\n",
       "         [-0.55494237,  0.31158292, -1.2159216 , ..., -1.005625  ,\n",
       "          -0.25399235,  0.84238523],\n",
       "         ...,\n",
       "         [-0.55821437,  0.34076935, -1.2563082 , ..., -1.043288  ,\n",
       "          -0.2827203 ,  0.8104075 ],\n",
       "         [-0.56318   ,  0.31000596, -1.2453939 , ..., -1.0294766 ,\n",
       "          -0.27874425,  0.8399347 ],\n",
       "         [-0.5426389 ,  0.2847454 , -1.2574663 , ..., -1.03963   ,\n",
       "          -0.31817642,  0.83914113]],\n",
       "\n",
       "        [[ 0.44867694, -0.11030793, -1.0612396 , ...,  0.15938988,\n",
       "           1.3954068 , -0.8149323 ],\n",
       "         [ 0.48737913, -0.13507605, -1.0781829 , ...,  0.18255235,\n",
       "           1.4374099 , -0.8484498 ],\n",
       "         [ 0.483931  , -0.09887636, -1.0746602 , ...,  0.17338474,\n",
       "           1.3969941 , -0.81513476],\n",
       "         ...,\n",
       "         [ 0.50399244, -0.10928184, -1.0799916 , ...,  0.19494927,\n",
       "           1.3724079 , -0.82790613],\n",
       "         [ 0.48908842, -0.12273043, -1.0333246 , ...,  0.20873618,\n",
       "           1.3960083 , -0.7703991 ],\n",
       "         [ 0.48073688, -0.11762157, -1.0952805 , ...,  0.2139769 ,\n",
       "           1.3589256 , -0.8222954 ]]]], dtype=float32)>), (<tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.62132895,  0.564304  , -1.8275582 , ..., -1.1760898 ,\n",
       "          -0.23777509,  0.13262415],\n",
       "         [ 0.63033354,  0.57615864, -1.8377115 , ..., -1.176226  ,\n",
       "          -0.23329896,  0.11811599],\n",
       "         [ 0.59957504,  0.5915284 , -1.807957  , ..., -1.1395153 ,\n",
       "          -0.22439614,  0.10393646],\n",
       "         ...,\n",
       "         [ 0.63688284,  0.54164684, -1.8085127 , ..., -1.1140386 ,\n",
       "          -0.24582125,  0.08965683],\n",
       "         [ 0.6540277 ,  0.57903695, -1.8324285 , ..., -1.0935183 ,\n",
       "          -0.21772869,  0.1164386 ],\n",
       "         [ 0.6303569 ,  0.57002556, -1.8086454 , ..., -1.1488783 ,\n",
       "          -0.2268264 ,  0.11920139]],\n",
       "\n",
       "        [[ 0.05835664,  1.6342769 , -0.26555085, ...,  0.11237143,\n",
       "           0.44201443, -0.15509124],\n",
       "         [ 0.07412064,  1.6665182 , -0.27948684, ...,  0.08715153,\n",
       "           0.48192626, -0.17330867],\n",
       "         [ 0.08461607,  1.6577021 , -0.30651352, ...,  0.11650625,\n",
       "           0.41009328, -0.1441791 ],\n",
       "         ...,\n",
       "         [ 0.06951851,  1.6782864 , -0.31174445, ...,  0.0917913 ,\n",
       "           0.43031234, -0.15906242],\n",
       "         [ 0.06423396,  1.7246531 , -0.3051839 , ...,  0.10957524,\n",
       "           0.42285967, -0.14119938],\n",
       "         [ 0.05619174,  1.6650392 , -0.31576407, ...,  0.10533953,\n",
       "           0.43050954, -0.12330012]],\n",
       "\n",
       "        [[-2.4992552 ,  1.6866262 , -0.07609361, ...,  0.2588879 ,\n",
       "           1.7284304 , -0.54496396],\n",
       "         [-2.4945784 ,  1.7135892 , -0.10376862, ...,  0.29681265,\n",
       "           1.7584195 , -0.5391293 ],\n",
       "         [-2.4986138 ,  1.7253714 , -0.08075356, ...,  0.30520284,\n",
       "           1.7776694 , -0.5333669 ],\n",
       "         ...,\n",
       "         [-2.5071545 ,  1.7203603 , -0.06389788, ...,  0.3016541 ,\n",
       "           1.7178895 , -0.5455686 ],\n",
       "         [-2.4915907 ,  1.7548006 , -0.07856387, ...,  0.29391527,\n",
       "           1.7505996 , -0.5700636 ],\n",
       "         [-2.5238583 ,  1.6897408 , -0.0439913 , ...,  0.29025567,\n",
       "           1.732947  , -0.5304631 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.8978626 ,  0.7809781 ,  0.15036887, ..., -0.05429615,\n",
       "          -0.7263034 , -1.3052592 ],\n",
       "         [-0.9043355 ,  0.7678366 ,  0.15088779, ..., -0.11755712,\n",
       "          -0.72931594, -1.3571099 ],\n",
       "         [-0.8965386 ,  0.7519935 ,  0.16284615, ..., -0.09481078,\n",
       "          -0.745979  , -1.368001  ],\n",
       "         ...,\n",
       "         [-0.8696942 ,  0.7533337 ,  0.14358658, ..., -0.03554146,\n",
       "          -0.7706178 , -1.3220167 ],\n",
       "         [-0.84648854,  0.7705238 ,  0.14808565, ..., -0.13395253,\n",
       "          -0.7426538 , -1.2947992 ],\n",
       "         [-0.89601713,  0.7391124 ,  0.18112993, ..., -0.06918201,\n",
       "          -0.7730888 , -1.3531104 ]],\n",
       "\n",
       "        [[ 1.4686633 , -0.44851083, -0.31740457, ..., -1.4545064 ,\n",
       "          -0.02394789,  0.20105422],\n",
       "         [ 1.4536495 , -0.47009546, -0.37247723, ..., -1.4633384 ,\n",
       "           0.00832969,  0.2300725 ],\n",
       "         [ 1.4586834 , -0.428927  , -0.35819733, ..., -1.4847621 ,\n",
       "           0.03262755,  0.19094682],\n",
       "         ...,\n",
       "         [ 1.4305351 , -0.4241366 , -0.33983827, ..., -1.4530137 ,\n",
       "           0.04269271,  0.24271774],\n",
       "         [ 1.446624  , -0.4416843 , -0.3348086 , ..., -1.4405239 ,\n",
       "           0.01008691,  0.20009816],\n",
       "         [ 1.4513677 , -0.40614432, -0.3041922 , ..., -1.4572141 ,\n",
       "           0.06672748,  0.21347094]],\n",
       "\n",
       "        [[-0.10210621,  0.61901313,  0.45629972, ..., -0.92666715,\n",
       "          -1.7471582 , -0.2073875 ],\n",
       "         [-0.1157625 ,  0.6500011 ,  0.4543727 , ..., -0.9371659 ,\n",
       "          -1.7035465 , -0.16240788],\n",
       "         [-0.10165337,  0.6394816 ,  0.4571508 , ..., -0.93449515,\n",
       "          -1.6988714 , -0.14544278],\n",
       "         ...,\n",
       "         [-0.13321254,  0.64639574,  0.45104587, ..., -0.9852066 ,\n",
       "          -1.7051431 , -0.19567543],\n",
       "         [-0.09587778,  0.6371757 ,  0.46725824, ..., -0.97027826,\n",
       "          -1.7116865 , -0.20764804],\n",
       "         [-0.11440334,  0.6099061 ,  0.43911383, ..., -0.9592964 ,\n",
       "          -1.6989853 , -0.19211328]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 1.88158977e+00, -1.65505171e-01,  4.49759841e-01, ...,\n",
       "           6.14888489e-01,  4.93232697e-01, -1.08603215e+00],\n",
       "         [ 1.87396216e+00, -1.49938345e-01,  4.62894738e-01, ...,\n",
       "           5.61195731e-01,  5.06442308e-01, -1.09077787e+00],\n",
       "         [ 1.90045714e+00, -1.35049164e-01,  4.71719205e-01, ...,\n",
       "           6.32616580e-01,  5.36234796e-01, -1.07421374e+00],\n",
       "         ...,\n",
       "         [ 1.82596433e+00, -1.66084081e-01,  4.23033893e-01, ...,\n",
       "           6.35031223e-01,  5.18690467e-01, -1.09375918e+00],\n",
       "         [ 1.82322156e+00, -1.44922286e-01,  4.45350409e-01, ...,\n",
       "           6.84476197e-01,  5.16321659e-01, -1.11513519e+00],\n",
       "         [ 1.83007252e+00, -1.49977237e-01,  4.12297428e-01, ...,\n",
       "           5.98002911e-01,  5.53038359e-01, -1.08274579e+00]],\n",
       "\n",
       "        [[-6.15566552e-01,  7.52496719e-01, -2.70510435e-01, ...,\n",
       "          -1.13323236e+00, -5.16519547e-02,  1.06240189e+00],\n",
       "         [-5.84223330e-01,  7.43166447e-01, -2.43508503e-01, ...,\n",
       "          -1.14517879e+00, -5.68536520e-02,  1.09253371e+00],\n",
       "         [-6.01654053e-01,  7.31916785e-01, -2.76795328e-01, ...,\n",
       "          -1.12453043e+00, -2.22740173e-02,  1.09375405e+00],\n",
       "         ...,\n",
       "         [-6.14669561e-01,  7.26038098e-01, -2.60903269e-01, ...,\n",
       "          -1.10856688e+00, -8.92860889e-02,  1.07795560e+00],\n",
       "         [-6.02633893e-01,  7.41948843e-01, -2.35271275e-01, ...,\n",
       "          -1.11549008e+00, -7.08900690e-02,  1.08184958e+00],\n",
       "         [-6.36103928e-01,  7.09765196e-01, -2.58534640e-01, ...,\n",
       "          -1.09581673e+00, -7.59664178e-02,  1.07290339e+00]],\n",
       "\n",
       "        [[-3.43308985e-01,  7.44979918e-01,  9.27992761e-02, ...,\n",
       "          -2.14412522e+00,  6.16808653e-01, -2.23702955e+00],\n",
       "         [-3.29704404e-01,  7.50021696e-01,  1.12175748e-01, ...,\n",
       "          -2.17225647e+00,  5.37515879e-01, -2.20257854e+00],\n",
       "         [-3.50521266e-01,  7.20851541e-01,  1.11213595e-01, ...,\n",
       "          -2.19179559e+00,  5.78235805e-01, -2.19502878e+00],\n",
       "         ...,\n",
       "         [-3.34050119e-01,  7.47166395e-01,  1.36060998e-01, ...,\n",
       "          -2.16179156e+00,  5.45473933e-01, -2.24177241e+00],\n",
       "         [-3.39374125e-01,  7.86288738e-01,  9.11353976e-02, ...,\n",
       "          -2.19297695e+00,  5.58114707e-01, -2.22179556e+00],\n",
       "         [-3.53169858e-01,  7.51605332e-01,  1.21363968e-01, ...,\n",
       "          -2.17048955e+00,  5.34384608e-01, -2.24983740e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.23197269e-01,  1.05548739e-01, -1.44621372e+00, ...,\n",
       "          -2.44231868e+00,  1.41750276e+00, -1.05324137e+00],\n",
       "         [-4.43713129e-01,  1.58911854e-01, -1.43759131e+00, ...,\n",
       "          -2.50076461e+00,  1.41773319e+00, -1.08484638e+00],\n",
       "         [-4.42258328e-01,  1.36492059e-01, -1.41974568e+00, ...,\n",
       "          -2.50801778e+00,  1.39342046e+00, -1.08486295e+00],\n",
       "         ...,\n",
       "         [-3.87416750e-01,  1.26759708e-01, -1.46289515e+00, ...,\n",
       "          -2.44003153e+00,  1.44554138e+00, -1.09261131e+00],\n",
       "         [-4.01701808e-01,  1.10552028e-01, -1.45731997e+00, ...,\n",
       "          -2.44932604e+00,  1.46775365e+00, -1.09054756e+00],\n",
       "         [-4.10515606e-01,  1.52298838e-01, -1.43937206e+00, ...,\n",
       "          -2.42616272e+00,  1.43161798e+00, -1.07328439e+00]],\n",
       "\n",
       "        [[ 5.98127246e-02, -1.63115788e+00,  2.80618191e-01, ...,\n",
       "          -1.27090216e-02, -5.82696438e-01,  5.85907996e-02],\n",
       "         [ 2.34220326e-02, -1.66203773e+00,  2.78368175e-01, ...,\n",
       "           2.71161199e-02, -5.79077423e-01,  8.17201734e-02],\n",
       "         [-2.45806575e-02, -1.70665598e+00,  2.93704867e-01, ...,\n",
       "          -2.05394626e-02, -5.72294593e-01,  1.01400197e-01],\n",
       "         ...,\n",
       "         [ 2.40108669e-02, -1.71557975e+00,  2.66024649e-01, ...,\n",
       "           1.19962692e-02, -6.16158545e-01,  1.16870463e-01],\n",
       "         [ 5.81842661e-03, -1.70891070e+00,  2.56181180e-01, ...,\n",
       "          -3.35597992e-03, -6.06188595e-01,  1.12495035e-01],\n",
       "         [-1.76657438e-02, -1.69555259e+00,  2.68597424e-01, ...,\n",
       "          -1.36613846e-03, -6.06957793e-01,  1.12541109e-01]],\n",
       "\n",
       "        [[-6.28553748e-01,  5.61010897e-01, -3.98078620e-01, ...,\n",
       "          -7.67019153e-01,  1.97716713e+00, -9.25661325e-02],\n",
       "         [-6.50778949e-01,  5.87655067e-01, -3.71898204e-01, ...,\n",
       "          -7.79543519e-01,  1.96290040e+00, -1.01190329e-01],\n",
       "         [-6.55729294e-01,  5.65972388e-01, -3.80767971e-01, ...,\n",
       "          -8.11922789e-01,  2.02126575e+00, -1.31561339e-01],\n",
       "         ...,\n",
       "         [-5.94689369e-01,  5.32667935e-01, -3.56818646e-01, ...,\n",
       "          -8.31637383e-01,  1.95789790e+00, -1.27644122e-01],\n",
       "         [-6.47366285e-01,  5.24949968e-01, -3.82300228e-01, ...,\n",
       "          -7.69711196e-01,  1.97519779e+00, -1.16943359e-01],\n",
       "         [-6.32825851e-01,  5.03384769e-01, -3.58239770e-01, ...,\n",
       "          -7.60640383e-01,  1.97197247e+00, -1.42061591e-01]]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.53038424, -0.07964937,  0.05354029, ...,  1.231214  ,\n",
       "          -1.2275951 ,  1.080338  ],\n",
       "         [ 0.5354048 , -0.07610323,  0.05977577, ...,  1.2529461 ,\n",
       "          -1.2663877 ,  1.048228  ],\n",
       "         [ 0.5197486 , -0.09868237,  0.0429416 , ...,  1.2026987 ,\n",
       "          -1.2748404 ,  1.064915  ],\n",
       "         ...,\n",
       "         [ 0.52190864, -0.09651231,  0.01204869, ...,  1.2405865 ,\n",
       "          -1.245621  ,  1.0844096 ],\n",
       "         [ 0.5568474 , -0.07891983, -0.00660579, ...,  1.2308909 ,\n",
       "          -1.272043  ,  1.0947144 ],\n",
       "         [ 0.5368865 , -0.1155225 ,  0.03805175, ...,  1.245136  ,\n",
       "          -1.2742102 ,  1.0664469 ]],\n",
       "\n",
       "        [[-0.18434644, -0.5425189 , -1.5141556 , ..., -1.3155601 ,\n",
       "           1.7069083 ,  0.26987442],\n",
       "         [-0.14198816, -0.53941184, -1.5254207 , ..., -1.3067553 ,\n",
       "           1.7346083 ,  0.30823916],\n",
       "         [-0.16788447, -0.5668061 , -1.488833  , ..., -1.3303081 ,\n",
       "           1.7226596 ,  0.2514186 ],\n",
       "         ...,\n",
       "         [-0.15912586, -0.5332445 , -1.4937901 , ..., -1.2836621 ,\n",
       "           1.7555127 ,  0.23483957],\n",
       "         [-0.1779083 , -0.52268624, -1.5267282 , ..., -1.3006063 ,\n",
       "           1.6895871 ,  0.27181304],\n",
       "         [-0.15908432, -0.53536415, -1.5289508 , ..., -1.2876713 ,\n",
       "           1.7166169 ,  0.26544654]],\n",
       "\n",
       "        [[ 0.8616021 ,  1.085479  ,  2.6791253 , ..., -0.518851  ,\n",
       "           1.1123449 , -0.10673916],\n",
       "         [ 0.85000104,  1.0986007 ,  2.6847248 , ..., -0.51458436,\n",
       "           1.107058  , -0.08809999],\n",
       "         [ 0.911085  ,  1.1148269 ,  2.6987176 , ..., -0.535627  ,\n",
       "           1.1363876 , -0.11057237],\n",
       "         ...,\n",
       "         [ 0.8806932 ,  1.1179682 ,  2.684908  , ..., -0.51459026,\n",
       "           1.1329223 , -0.08524731],\n",
       "         [ 0.8898202 ,  1.1157393 ,  2.66411   , ..., -0.483009  ,\n",
       "           1.1550407 , -0.10763827],\n",
       "         [ 0.8903433 ,  1.0899757 ,  2.6941423 , ..., -0.4980322 ,\n",
       "           1.1385919 , -0.09121799]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.33115083, -2.63575   ,  1.2500093 , ..., -0.50239015,\n",
       "           0.42291158, -1.697852  ],\n",
       "         [ 0.35557157, -2.6192207 ,  1.2753719 , ..., -0.44060832,\n",
       "           0.38103297, -1.7284544 ],\n",
       "         [ 0.33348995, -2.6236472 ,  1.2624577 , ..., -0.45154202,\n",
       "           0.39554304, -1.7045338 ],\n",
       "         ...,\n",
       "         [ 0.31055766, -2.6187296 ,  1.2730677 , ..., -0.46705216,\n",
       "           0.4086047 , -1.6499712 ],\n",
       "         [ 0.35386592, -2.6397076 ,  1.2812881 , ..., -0.44324094,\n",
       "           0.42866674, -1.6729695 ],\n",
       "         [ 0.32074285, -2.6024213 ,  1.2609444 , ..., -0.47985741,\n",
       "           0.41885257, -1.6949364 ]],\n",
       "\n",
       "        [[-0.66807234,  1.7852275 ,  1.7449982 , ..., -1.0828166 ,\n",
       "          -1.3411995 , -0.2251885 ],\n",
       "         [-0.68912387,  1.7434591 ,  1.7898289 , ..., -1.1006204 ,\n",
       "          -1.3767908 , -0.24861856],\n",
       "         [-0.64543706,  1.7431093 ,  1.7648354 , ..., -1.0801332 ,\n",
       "          -1.3501482 , -0.20383497],\n",
       "         ...,\n",
       "         [-0.6829101 ,  1.7878098 ,  1.7470195 , ..., -1.0971884 ,\n",
       "          -1.3229836 , -0.24786593],\n",
       "         [-0.66066325,  1.7385002 ,  1.7545105 , ..., -1.0729353 ,\n",
       "          -1.32687   , -0.25356093],\n",
       "         [-0.62890327,  1.7978723 ,  1.7422401 , ..., -1.079218  ,\n",
       "          -1.340688  , -0.26409078]],\n",
       "\n",
       "        [[-0.33973953,  0.13779539,  1.458662  , ..., -0.3563398 ,\n",
       "           0.07501733,  0.964738  ],\n",
       "         [-0.35231176,  0.12138978,  1.4425347 , ..., -0.36977047,\n",
       "           0.09634578,  0.95808524],\n",
       "         [-0.3592836 ,  0.15564674,  1.426439  , ..., -0.34690106,\n",
       "           0.11465415,  0.9870446 ],\n",
       "         ...,\n",
       "         [-0.35475966,  0.09785199,  1.4488306 , ..., -0.3540925 ,\n",
       "           0.09923419,  0.94354033],\n",
       "         [-0.3380713 ,  0.15189317,  1.4386711 , ..., -0.3653034 ,\n",
       "           0.0963266 ,  0.95959353],\n",
       "         [-0.35805613,  0.13740426,  1.4773822 , ..., -0.33415395,\n",
       "           0.09555812,  0.97227615]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-2.4045181 , -0.9072702 , -0.20807996, ...,  0.6687043 ,\n",
       "           1.1260993 ,  0.38811335],\n",
       "         [-2.4313598 , -0.9146573 , -0.16543397, ...,  0.6962763 ,\n",
       "           1.1138998 ,  0.40909675],\n",
       "         [-2.4259048 , -0.91894436, -0.18813254, ...,  0.67379475,\n",
       "           1.1103262 ,  0.41245118],\n",
       "         ...,\n",
       "         [-2.4013557 , -0.9391762 , -0.21231385, ...,  0.68714935,\n",
       "           1.09131   ,  0.39983758],\n",
       "         [-2.4120078 , -0.90402424, -0.16329305, ...,  0.7021032 ,\n",
       "           1.1039758 ,  0.36038026],\n",
       "         [-2.4255552 , -0.90744007, -0.19289184, ...,  0.6739851 ,\n",
       "           1.1313813 ,  0.3921235 ]],\n",
       "\n",
       "        [[-0.121292  ,  0.35688412,  1.0958338 , ...,  0.7707301 ,\n",
       "          -0.25879014, -0.58437014],\n",
       "         [-0.09715927,  0.37424374,  1.0616708 , ...,  0.7773205 ,\n",
       "          -0.2710585 , -0.60504216],\n",
       "         [-0.07916909,  0.34493518,  1.0602298 , ...,  0.7860818 ,\n",
       "          -0.24565426, -0.61408055],\n",
       "         ...,\n",
       "         [-0.11089265,  0.34260154,  1.0774823 , ...,  0.7933686 ,\n",
       "          -0.23809469, -0.6204499 ],\n",
       "         [-0.1338396 ,  0.34571657,  1.0782611 , ...,  0.7661798 ,\n",
       "          -0.2285577 , -0.59220886],\n",
       "         [-0.11327106,  0.32187575,  1.0813786 , ...,  0.7661152 ,\n",
       "          -0.23974526, -0.59894454]],\n",
       "\n",
       "        [[-1.8508816 ,  0.38751984, -1.0605103 , ...,  0.5817546 ,\n",
       "          -1.7406379 ,  0.844672  ],\n",
       "         [-1.815559  ,  0.38830423, -1.041373  , ...,  0.5605842 ,\n",
       "          -1.7868508 ,  0.8054523 ],\n",
       "         [-1.8237042 ,  0.3622499 , -1.0696893 , ...,  0.59261096,\n",
       "          -1.7503821 ,  0.80362827],\n",
       "         ...,\n",
       "         [-1.8438557 ,  0.40310127, -1.0513198 , ...,  0.60010767,\n",
       "          -1.7496799 ,  0.81137055],\n",
       "         [-1.8246279 ,  0.39704692, -1.0392225 , ...,  0.5362168 ,\n",
       "          -1.7774351 ,  0.78976905],\n",
       "         [-1.8204281 ,  0.4084443 , -1.0537608 , ...,  0.56751144,\n",
       "          -1.7551718 ,  0.7829419 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.1569475 ,  0.53830934, -0.3014919 , ...,  0.27011752,\n",
       "           0.35295594,  0.2007904 ],\n",
       "         [ 1.157118  ,  0.52939916, -0.28133172, ...,  0.27589935,\n",
       "           0.29343432,  0.20836756],\n",
       "         [ 1.1706399 ,  0.54731923, -0.26421174, ...,  0.27145928,\n",
       "           0.31028116,  0.17924806],\n",
       "         ...,\n",
       "         [ 1.1577319 ,  0.5275688 , -0.26400316, ...,  0.2413193 ,\n",
       "           0.34431636,  0.16583928],\n",
       "         [ 1.1745744 ,  0.548706  , -0.30163738, ...,  0.2777933 ,\n",
       "           0.32512414,  0.21051082],\n",
       "         [ 1.1459367 ,  0.55926836, -0.24213818, ...,  0.2945339 ,\n",
       "           0.32829028,  0.2001662 ]],\n",
       "\n",
       "        [[ 0.3666674 ,  1.3853558 , -1.7407557 , ...,  2.1708717 ,\n",
       "          -1.1200411 ,  1.0471324 ],\n",
       "         [ 0.3198458 ,  1.370704  , -1.7295041 , ...,  2.1633236 ,\n",
       "          -1.1281823 ,  1.0567381 ],\n",
       "         [ 0.34989196,  1.3931668 , -1.733095  , ...,  2.1904109 ,\n",
       "          -1.1352291 ,  1.036397  ],\n",
       "         ...,\n",
       "         [ 0.31261563,  1.3906165 , -1.7406528 , ...,  2.185967  ,\n",
       "          -1.1217935 ,  1.0480665 ],\n",
       "         [ 0.33697623,  1.3974762 , -1.7482758 , ...,  2.209833  ,\n",
       "          -1.151284  ,  1.0626199 ],\n",
       "         [ 0.33089662,  1.4008614 , -1.7226918 , ...,  2.1749735 ,\n",
       "          -1.139231  ,  1.0513334 ]],\n",
       "\n",
       "        [[ 1.6859758 , -0.16517168, -0.7939162 , ..., -0.26522657,\n",
       "          -1.5786299 ,  0.6330948 ],\n",
       "         [ 1.6683738 , -0.16682208, -0.766023  , ..., -0.21441743,\n",
       "          -1.5612528 ,  0.6486564 ],\n",
       "         [ 1.6474625 , -0.15567106, -0.785889  , ..., -0.24764836,\n",
       "          -1.5566111 ,  0.6213879 ],\n",
       "         ...,\n",
       "         [ 1.6603094 , -0.16632316, -0.78973794, ..., -0.2504936 ,\n",
       "          -1.5540671 ,  0.6363176 ],\n",
       "         [ 1.6591531 , -0.16054264, -0.8046973 , ..., -0.2945468 ,\n",
       "          -1.5477755 ,  0.62516725],\n",
       "         [ 1.6749423 , -0.16393322, -0.8159863 , ..., -0.28960702,\n",
       "          -1.529829  ,  0.61998194]]]], dtype=float32)>), (<tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.13548964,  0.16711193,  0.1238516 , ..., -0.02239752,\n",
       "          -2.1283586 , -0.48481092],\n",
       "         [ 0.13478726,  0.12145734,  0.13266027, ..., -0.02424437,\n",
       "          -2.1166172 , -0.47500694],\n",
       "         [ 0.10483181,  0.15045398,  0.13531417, ..., -0.02575195,\n",
       "          -2.1416335 , -0.4610336 ],\n",
       "         ...,\n",
       "         [ 0.10267603,  0.14762866,  0.10514534, ..., -0.06237918,\n",
       "          -2.1659827 , -0.4855409 ],\n",
       "         [ 0.10273725,  0.18580812,  0.13310397, ..., -0.0382145 ,\n",
       "          -2.1587975 , -0.46169704],\n",
       "         [ 0.07392347,  0.1739456 ,  0.15218085, ..., -0.02916232,\n",
       "          -2.118646  , -0.49019814]],\n",
       "\n",
       "        [[ 0.9261561 ,  1.0004486 ,  0.26039296, ...,  0.63129276,\n",
       "           1.0230272 ,  0.09762695],\n",
       "         [ 0.9350958 ,  1.0045089 ,  0.25806627, ...,  0.6441126 ,\n",
       "           1.0299001 ,  0.13649905],\n",
       "         [ 0.96510476,  1.0099137 ,  0.2686115 , ...,  0.63611   ,\n",
       "           1.0167313 ,  0.12389603],\n",
       "         ...,\n",
       "         [ 0.9436674 ,  1.0199138 ,  0.2714821 , ...,  0.5821161 ,\n",
       "           1.0095308 ,  0.09497756],\n",
       "         [ 0.9405958 ,  1.0082433 ,  0.25556272, ...,  0.62695587,\n",
       "           1.0104854 ,  0.12673622],\n",
       "         [ 0.97770786,  1.0144377 ,  0.26756507, ...,  0.6251344 ,\n",
       "           1.0198731 ,  0.11656031]],\n",
       "\n",
       "        [[ 0.20674232,  0.28859946, -0.8887397 , ..., -0.22896081,\n",
       "          -0.6770264 ,  1.059733  ],\n",
       "         [ 0.20269209,  0.31027773, -0.9263356 , ..., -0.25421757,\n",
       "          -0.69247603,  1.043573  ],\n",
       "         [ 0.22241476,  0.3205541 , -0.9333221 , ..., -0.22133195,\n",
       "          -0.68981004,  1.0838926 ],\n",
       "         ...,\n",
       "         [ 0.21993655,  0.30552885, -0.9134966 , ..., -0.23806787,\n",
       "          -0.70308095,  1.0663381 ],\n",
       "         [ 0.20922574,  0.31601983, -0.9039828 , ..., -0.249872  ,\n",
       "          -0.7233434 ,  1.0183281 ],\n",
       "         [ 0.1786649 ,  0.27715114, -0.9183017 , ..., -0.23663315,\n",
       "          -0.67405975,  1.041251  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.4593751 ,  1.1979921 ,  0.12400967, ...,  0.1995532 ,\n",
       "          -0.42110077, -1.2665493 ],\n",
       "         [-1.4864905 ,  1.199128  ,  0.04268026, ...,  0.20253375,\n",
       "          -0.44243854, -1.2644686 ],\n",
       "         [-1.482259  ,  1.2060282 ,  0.05346441, ...,  0.20794696,\n",
       "          -0.42215508, -1.2378429 ],\n",
       "         ...,\n",
       "         [-1.4867461 ,  1.175319  ,  0.08367997, ...,  0.15364021,\n",
       "          -0.40939152, -1.2156961 ],\n",
       "         [-1.4693668 ,  1.180356  ,  0.06394684, ...,  0.15649429,\n",
       "          -0.42426458, -1.2839204 ],\n",
       "         [-1.485789  ,  1.15664   ,  0.07656282, ...,  0.18451115,\n",
       "          -0.43930092, -1.2398922 ]],\n",
       "\n",
       "        [[-0.33899212,  0.50034136,  1.2066864 , ...,  0.8289751 ,\n",
       "          -1.1937305 ,  0.22879082],\n",
       "         [-0.360215  ,  0.4744295 ,  1.2034435 , ...,  0.8348253 ,\n",
       "          -1.2120016 ,  0.2280932 ],\n",
       "         [-0.4022874 ,  0.44920135,  1.1898665 , ...,  0.8153425 ,\n",
       "          -1.2143314 ,  0.21877694],\n",
       "         ...,\n",
       "         [-0.3447507 ,  0.4900393 ,  1.1932493 , ...,  0.8057547 ,\n",
       "          -1.1691936 ,  0.2048049 ],\n",
       "         [-0.33214477,  0.47676396,  1.2048273 , ...,  0.80598974,\n",
       "          -1.2076834 ,  0.21328795],\n",
       "         [-0.34309822,  0.4658598 ,  1.1820531 , ...,  0.8178557 ,\n",
       "          -1.1952407 ,  0.19385064]],\n",
       "\n",
       "        [[ 0.48451522, -0.7598893 , -0.5500978 , ..., -0.14056623,\n",
       "          -1.2889245 ,  0.35874572],\n",
       "         [ 0.5009159 , -0.73438776, -0.56389993, ..., -0.1456449 ,\n",
       "          -1.2782488 ,  0.37057316],\n",
       "         [ 0.49891979, -0.78057754, -0.5425946 , ..., -0.17464793,\n",
       "          -1.3156313 ,  0.35560706],\n",
       "         ...,\n",
       "         [ 0.4913422 , -0.7891973 , -0.5480009 , ..., -0.16505158,\n",
       "          -1.315511  ,  0.3461394 ],\n",
       "         [ 0.47417825, -0.79575825, -0.5369489 , ..., -0.16917682,\n",
       "          -1.3522942 ,  0.34496036],\n",
       "         [ 0.5390904 , -0.7795254 , -0.5592257 , ..., -0.15963459,\n",
       "          -1.3300774 ,  0.34979552]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 1.40418828e+00,  1.13784599e+00, -1.07040569e-01, ...,\n",
       "           5.31786501e-01,  1.46551180e+00,  1.08370185e+00],\n",
       "         [ 1.38865757e+00,  1.10857797e+00, -1.01711422e-01, ...,\n",
       "           5.30329466e-01,  1.47016311e+00,  1.07906711e+00],\n",
       "         [ 1.40889263e+00,  1.09939933e+00, -9.18331593e-02, ...,\n",
       "           5.23076773e-01,  1.49492800e+00,  1.07190013e+00],\n",
       "         ...,\n",
       "         [ 1.41200125e+00,  1.09021223e+00, -1.26300901e-01, ...,\n",
       "           5.33790410e-01,  1.46960831e+00,  1.05968201e+00],\n",
       "         [ 1.37839866e+00,  1.12256289e+00, -9.98051912e-02, ...,\n",
       "           5.26338577e-01,  1.45677769e+00,  1.08670545e+00],\n",
       "         [ 1.38110900e+00,  1.12226844e+00, -1.03127316e-01, ...,\n",
       "           5.09517789e-01,  1.50114191e+00,  1.06876540e+00]],\n",
       "\n",
       "        [[ 3.56308162e-01,  3.47480416e-01,  8.42267752e-01, ...,\n",
       "          -6.14445508e-02,  7.91180134e-02, -1.19216764e+00],\n",
       "         [ 3.57808411e-01,  3.53466213e-01,  8.36031377e-01, ...,\n",
       "          -5.61623573e-02,  2.05732584e-02, -1.19475675e+00],\n",
       "         [ 3.61052752e-01,  3.73714983e-01,  8.57881665e-01, ...,\n",
       "          -5.84406257e-02,  4.75361347e-02, -1.19711208e+00],\n",
       "         ...,\n",
       "         [ 3.40299308e-01,  3.92028093e-01,  8.38244796e-01, ...,\n",
       "          -5.10793328e-02, -6.06763363e-03, -1.16052997e+00],\n",
       "         [ 3.41113538e-01,  3.92578304e-01,  8.43085110e-01, ...,\n",
       "          -6.64036274e-02,  1.12224817e-02, -1.14581132e+00],\n",
       "         [ 3.40201229e-01,  3.91905636e-01,  8.65815878e-01, ...,\n",
       "          -8.51082504e-02,  2.06197500e-02, -1.15730834e+00]],\n",
       "\n",
       "        [[ 1.23455000e+00, -9.42719698e-01, -6.02536559e-01, ...,\n",
       "           3.66712630e-01, -1.31551909e+00, -9.86059904e-01],\n",
       "         [ 1.23413503e+00, -9.56304610e-01, -6.19297743e-01, ...,\n",
       "           3.48842680e-01, -1.29454541e+00, -9.90079522e-01],\n",
       "         [ 1.19258046e+00, -9.88859773e-01, -6.07985497e-01, ...,\n",
       "           3.94730330e-01, -1.29355884e+00, -9.81253028e-01],\n",
       "         ...,\n",
       "         [ 1.24212086e+00, -9.36178446e-01, -6.38843119e-01, ...,\n",
       "           3.20139915e-01, -1.34088826e+00, -9.60010111e-01],\n",
       "         [ 1.25654590e+00, -9.60384607e-01, -6.29707932e-01, ...,\n",
       "           3.07669491e-01, -1.34990680e+00, -9.62284207e-01],\n",
       "         [ 1.21843958e+00, -9.61387038e-01, -5.92442274e-01, ...,\n",
       "           3.47246408e-01, -1.32298303e+00, -9.78776336e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.64458239e-01, -7.44956017e-01, -4.51301038e-03, ...,\n",
       "           1.58163413e-01, -4.76668358e-01, -1.82594788e+00],\n",
       "         [-2.54135191e-01, -7.44762540e-01,  1.33956969e-02, ...,\n",
       "           1.56177625e-01, -4.50881720e-01, -1.78985274e+00],\n",
       "         [-2.26940632e-01, -7.37357855e-01,  6.16747141e-03, ...,\n",
       "           1.61161453e-01, -4.30699110e-01, -1.74464917e+00],\n",
       "         ...,\n",
       "         [-1.94867492e-01, -7.48374343e-01, -1.01095438e-03, ...,\n",
       "           1.26845926e-01, -4.49977994e-01, -1.77501857e+00],\n",
       "         [-2.22358644e-01, -7.56826282e-01, -5.46598434e-03, ...,\n",
       "           1.13822877e-01, -4.50661302e-01, -1.77517307e+00],\n",
       "         [-2.00284719e-01, -7.24472404e-01,  2.34909356e-02, ...,\n",
       "           1.46741554e-01, -4.38322067e-01, -1.79875803e+00]],\n",
       "\n",
       "        [[ 1.01400745e+00, -3.97046179e-01,  1.90615684e-01, ...,\n",
       "          -1.98180640e+00,  6.08876348e-01,  5.85809469e-01],\n",
       "         [ 9.91497874e-01, -3.49686027e-01,  1.85017869e-01, ...,\n",
       "          -1.97855365e+00,  5.88204026e-01,  5.99774063e-01],\n",
       "         [ 1.01499712e+00, -3.82361829e-01,  2.04608679e-01, ...,\n",
       "          -2.02173853e+00,  5.98711252e-01,  5.69348752e-01],\n",
       "         ...,\n",
       "         [ 9.93757725e-01, -3.92306775e-01,  1.78033739e-01, ...,\n",
       "          -1.97475123e+00,  6.03253841e-01,  5.80104887e-01],\n",
       "         [ 1.02071249e+00, -3.75008196e-01,  1.86134428e-01, ...,\n",
       "          -1.96735632e+00,  5.99535644e-01,  5.73812544e-01],\n",
       "         [ 9.92010951e-01, -3.61639321e-01,  1.80508375e-01, ...,\n",
       "          -1.96347988e+00,  5.94056010e-01,  5.34305215e-01]],\n",
       "\n",
       "        [[-1.61255431e+00,  9.66105461e-01, -3.01542282e-02, ...,\n",
       "          -2.48448420e+00, -1.41270995e-01,  3.91774416e-01],\n",
       "         [-1.60353637e+00,  9.85730410e-01, -1.86642110e-02, ...,\n",
       "          -2.49782872e+00, -1.31936014e-01,  3.56959701e-01],\n",
       "         [-1.64972949e+00,  9.47629631e-01, -1.81179345e-02, ...,\n",
       "          -2.48379374e+00, -1.37682617e-01,  3.89131129e-01],\n",
       "         ...,\n",
       "         [-1.65593243e+00,  1.01321757e+00, -7.52341747e-03, ...,\n",
       "          -2.45187902e+00, -1.49500608e-01,  3.58917296e-01],\n",
       "         [-1.64939618e+00,  9.90106821e-01, -3.34496945e-02, ...,\n",
       "          -2.46139336e+00, -1.63339496e-01,  3.80569994e-01],\n",
       "         [-1.67507982e+00,  9.93718505e-01, -1.35712028e-02, ...,\n",
       "          -2.46500778e+00, -1.63673162e-01,  3.97997320e-01]]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 1.33089685e+00, -1.29814410e+00, -8.64593208e-01, ...,\n",
       "          -5.73625743e-01, -2.35198641e+00,  1.06635869e+00],\n",
       "         [ 1.31164825e+00, -1.30341649e+00, -8.53145361e-01, ...,\n",
       "          -5.28399110e-01, -2.35261536e+00,  1.03105938e+00],\n",
       "         [ 1.31414020e+00, -1.29194522e+00, -8.74584496e-01, ...,\n",
       "          -5.61750650e-01, -2.38482141e+00,  1.03338397e+00],\n",
       "         ...,\n",
       "         [ 1.29724479e+00, -1.29643822e+00, -8.86952996e-01, ...,\n",
       "          -5.50928771e-01, -2.40013051e+00,  1.03322375e+00],\n",
       "         [ 1.29364800e+00, -1.31258392e+00, -8.94502461e-01, ...,\n",
       "          -5.57816386e-01, -2.36794615e+00,  1.04039729e+00],\n",
       "         [ 1.31299746e+00, -1.34214163e+00, -8.86365056e-01, ...,\n",
       "          -5.20686626e-01, -2.36438394e+00,  1.03037190e+00]],\n",
       "\n",
       "        [[-1.58161521e+00, -1.09430671e+00, -5.83701730e-02, ...,\n",
       "          -1.15345418e+00,  5.63537240e-01, -5.11876702e-01],\n",
       "         [-1.57567215e+00, -1.11911225e+00, -4.29253280e-02, ...,\n",
       "          -1.11882472e+00,  6.14837587e-01, -4.94946092e-01],\n",
       "         [-1.58699059e+00, -1.14220154e+00, -5.13392985e-02, ...,\n",
       "          -1.12957764e+00,  5.39764643e-01, -4.79536653e-01],\n",
       "         ...,\n",
       "         [-1.60011959e+00, -1.11191916e+00, -4.77707386e-02, ...,\n",
       "          -1.11149311e+00,  5.74187398e-01, -4.92958754e-01],\n",
       "         [-1.56961954e+00, -1.12515187e+00, -2.28695571e-02, ...,\n",
       "          -1.11902690e+00,  5.65193474e-01, -4.69921976e-01],\n",
       "         [-1.58157742e+00, -1.10572219e+00, -3.40268016e-02, ...,\n",
       "          -1.15095353e+00,  5.62689066e-01, -4.64079767e-01]],\n",
       "\n",
       "        [[ 1.67271972e-01,  1.31352079e+00, -8.04722011e-01, ...,\n",
       "          -1.04415762e+00,  7.25033700e-01,  1.63882995e+00],\n",
       "         [ 1.76599681e-01,  1.37855208e+00, -8.34418237e-01, ...,\n",
       "          -1.03131914e+00,  7.12769270e-01,  1.62923586e+00],\n",
       "         [ 1.29725188e-01,  1.32019007e+00, -8.26948285e-01, ...,\n",
       "          -1.01208222e+00,  7.29844570e-01,  1.58934307e+00],\n",
       "         ...,\n",
       "         [ 1.55344024e-01,  1.33079672e+00, -8.03248823e-01, ...,\n",
       "          -1.00204957e+00,  7.26369381e-01,  1.60750556e+00],\n",
       "         [ 1.63881227e-01,  1.31152976e+00, -8.51255000e-01, ...,\n",
       "          -1.01667416e+00,  7.50332892e-01,  1.59929097e+00],\n",
       "         [ 1.31530792e-01,  1.33200681e+00, -7.84018576e-01, ...,\n",
       "          -1.04517448e+00,  7.11697459e-01,  1.62083137e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.51179624e-01,  1.01898342e-01,  1.30246150e+00, ...,\n",
       "          -3.50281096e+00,  2.40309238e-02,  5.74572265e-01],\n",
       "         [-9.56012189e-01,  1.15918100e-01,  1.32393479e+00, ...,\n",
       "          -3.50189781e+00, -3.63230705e-03,  5.58138430e-01],\n",
       "         [-9.73575115e-01,  1.22035384e-01,  1.31173992e+00, ...,\n",
       "          -3.52130127e+00,  1.21169090e-02,  5.59660852e-01],\n",
       "         ...,\n",
       "         [-9.44274962e-01,  1.43402040e-01,  1.33039284e+00, ...,\n",
       "          -3.54258847e+00,  2.31866837e-02,  5.63672602e-01],\n",
       "         [-9.77632523e-01,  1.27013892e-01,  1.30156612e+00, ...,\n",
       "          -3.53029871e+00,  1.85883045e-03,  5.70443153e-01],\n",
       "         [-9.33384538e-01,  1.06013060e-01,  1.31180048e+00, ...,\n",
       "          -3.50493002e+00,  6.13772869e-02,  6.00004733e-01]],\n",
       "\n",
       "        [[ 3.95925671e-01, -3.00667703e-01,  1.33719611e+00, ...,\n",
       "           1.56813550e+00, -7.23722339e-01, -1.06168568e-01],\n",
       "         [ 3.25512379e-01, -3.22010159e-01,  1.30568278e+00, ...,\n",
       "           1.56865048e+00, -7.26500332e-01, -1.21514559e-01],\n",
       "         [ 3.59984159e-01, -3.36268306e-01,  1.29339528e+00, ...,\n",
       "           1.57365727e+00, -7.27585912e-01, -1.37633324e-01],\n",
       "         ...,\n",
       "         [ 3.55443269e-01, -3.54392171e-01,  1.31433177e+00, ...,\n",
       "           1.55994749e+00, -7.28427410e-01, -1.32391274e-01],\n",
       "         [ 3.48179847e-01, -3.30010474e-01,  1.32527673e+00, ...,\n",
       "           1.56742537e+00, -7.52465427e-01, -1.34472638e-01],\n",
       "         [ 3.61343563e-01, -3.21403146e-01,  1.33884883e+00, ...,\n",
       "           1.57579303e+00, -7.47273922e-01, -1.54359847e-01]],\n",
       "\n",
       "        [[ 8.70877445e-01,  3.55337560e-02, -9.03939307e-01, ...,\n",
       "          -4.10081625e-01,  2.96789050e-01, -2.41100645e+00],\n",
       "         [ 8.98946047e-01,  1.68381333e-02, -9.40124929e-01, ...,\n",
       "          -4.08019185e-01,  3.33735049e-01, -2.41817498e+00],\n",
       "         [ 8.43708515e-01,  6.04322553e-03, -8.95948887e-01, ...,\n",
       "          -4.04619813e-01,  3.06961656e-01, -2.45495319e+00],\n",
       "         ...,\n",
       "         [ 8.69773507e-01, -6.55332208e-03, -8.92426670e-01, ...,\n",
       "          -4.11685348e-01,  2.97888696e-01, -2.42563224e+00],\n",
       "         [ 8.55699897e-01,  2.11079568e-02, -9.16710913e-01, ...,\n",
       "          -4.06766832e-01,  2.56311923e-01, -2.40617085e+00],\n",
       "         [ 8.69675517e-01,  9.15575027e-03, -8.92194986e-01, ...,\n",
       "          -4.35023010e-01,  3.14511240e-01, -2.42283201e+00]]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.30338758, -1.252393  , -0.33102328, ..., -0.29297608,\n",
       "           0.0318839 ,  1.246523  ],\n",
       "         [ 0.25429285, -1.2320747 , -0.31814855, ..., -0.29910725,\n",
       "          -0.02821833,  1.2670643 ],\n",
       "         [ 0.28510344, -1.2851739 , -0.3295345 , ..., -0.3094098 ,\n",
       "          -0.00465155,  1.2493012 ],\n",
       "         ...,\n",
       "         [ 0.25528133, -1.2619375 , -0.32388312, ..., -0.32356805,\n",
       "           0.02625448,  1.2609874 ],\n",
       "         [ 0.2995724 , -1.2753086 , -0.32449406, ..., -0.27073294,\n",
       "           0.03065258,  1.2448364 ],\n",
       "         [ 0.2734927 , -1.257003  , -0.3302564 , ..., -0.2953543 ,\n",
       "           0.05054289,  1.2502662 ]],\n",
       "\n",
       "        [[ 0.77836454, -2.0445428 , -0.9454141 , ..., -0.7323567 ,\n",
       "          -1.4000041 ,  1.5517864 ],\n",
       "         [ 0.78165305, -2.022719  , -0.9098387 , ..., -0.7025238 ,\n",
       "          -1.401737  ,  1.5221738 ],\n",
       "         [ 0.8052057 , -2.0440156 , -0.9654501 , ..., -0.73030484,\n",
       "          -1.425334  ,  1.5258615 ],\n",
       "         ...,\n",
       "         [ 0.768019  , -2.04983   , -0.95312506, ..., -0.7839936 ,\n",
       "          -1.3891594 ,  1.5321608 ],\n",
       "         [ 0.7760203 , -2.0525181 , -0.9579145 , ..., -0.71541363,\n",
       "          -1.3923068 ,  1.5319841 ],\n",
       "         [ 0.7842096 , -2.0246265 , -0.90602636, ..., -0.7167185 ,\n",
       "          -1.3994213 ,  1.5517236 ]],\n",
       "\n",
       "        [[ 1.4831228 , -1.3256135 , -1.2804613 , ..., -0.28533638,\n",
       "          -1.7760439 ,  1.6156956 ],\n",
       "         [ 1.4488947 , -1.3110414 , -1.3114395 , ..., -0.27899018,\n",
       "          -1.749549  ,  1.6316631 ],\n",
       "         [ 1.425117  , -1.3186464 , -1.2934208 , ..., -0.28277186,\n",
       "          -1.7745018 ,  1.6029642 ],\n",
       "         ...,\n",
       "         [ 1.4149022 , -1.3629895 , -1.2705302 , ..., -0.27572227,\n",
       "          -1.7739335 ,  1.608368  ],\n",
       "         [ 1.4430896 , -1.3240594 , -1.2893629 , ..., -0.32174087,\n",
       "          -1.7430522 ,  1.6111035 ],\n",
       "         [ 1.4487405 , -1.3325576 , -1.2907875 , ..., -0.28481963,\n",
       "          -1.7803212 ,  1.6004114 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4098433 ,  0.7782624 ,  0.46179906, ..., -0.25436443,\n",
       "           0.34420758,  0.9722785 ],\n",
       "         [-0.39351746,  0.7648497 ,  0.439712  , ..., -0.20320654,\n",
       "           0.37885463,  0.99151945],\n",
       "         [-0.43670654,  0.77649987,  0.4802401 , ..., -0.21656916,\n",
       "           0.38420656,  0.9813365 ],\n",
       "         ...,\n",
       "         [-0.42715615,  0.7735444 ,  0.4336499 , ..., -0.24389142,\n",
       "           0.36990422,  1.0158689 ],\n",
       "         [-0.41003728,  0.7771356 ,  0.4424314 , ..., -0.2614572 ,\n",
       "           0.3871357 ,  0.9825168 ],\n",
       "         [-0.43047857,  0.7692456 ,  0.43734032, ..., -0.25675717,\n",
       "           0.39703116,  0.9660238 ]],\n",
       "\n",
       "        [[-0.37243414,  1.1422176 ,  2.7376654 , ..., -3.0016117 ,\n",
       "           0.400007  , -0.21572772],\n",
       "         [-0.37632465,  1.1278436 ,  2.7525876 , ..., -2.9968715 ,\n",
       "           0.40287995, -0.19878551],\n",
       "         [-0.38301754,  1.1617386 ,  2.7335584 , ..., -2.9744916 ,\n",
       "           0.36374065, -0.21512243],\n",
       "         ...,\n",
       "         [-0.39590842,  1.1574726 ,  2.732131  , ..., -2.9541142 ,\n",
       "           0.33479398, -0.24539348],\n",
       "         [-0.39301175,  1.1030157 ,  2.7334347 , ..., -2.9780989 ,\n",
       "           0.37179396, -0.23767745],\n",
       "         [-0.37477815,  1.1526453 ,  2.7354617 , ..., -2.9863825 ,\n",
       "           0.3558922 , -0.2422243 ]],\n",
       "\n",
       "        [[-0.56642026,  1.5345545 , -0.17117098, ..., -0.87745804,\n",
       "           2.2650213 , -0.63669056],\n",
       "         [-0.5773797 ,  1.5518906 , -0.18814066, ..., -0.8639779 ,\n",
       "           2.1781914 , -0.5849385 ],\n",
       "         [-0.60931873,  1.5870888 , -0.1720596 , ..., -0.87339765,\n",
       "           2.241763  , -0.6215262 ],\n",
       "         ...,\n",
       "         [-0.58462393,  1.5552912 , -0.14575931, ..., -0.8481831 ,\n",
       "           2.2195678 , -0.6120952 ],\n",
       "         [-0.5725485 ,  1.5447731 , -0.1579451 , ..., -0.8512221 ,\n",
       "           2.1987605 , -0.6390259 ],\n",
       "         [-0.58999133,  1.57003   , -0.15500432, ..., -0.85598886,\n",
       "           2.2526934 , -0.61462677]]]], dtype=float32)>), (<tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-0.23474473,  0.700534  , -1.6132411 , ...,  0.6409843 ,\n",
       "          -0.07430789,  1.0346334 ],\n",
       "         [-0.20110029,  0.6928671 , -1.5846341 , ...,  0.6266737 ,\n",
       "          -0.05959719,  1.056133  ],\n",
       "         [-0.22290394,  0.6842808 , -1.5669963 , ...,  0.6472634 ,\n",
       "          -0.10049728,  1.0414205 ],\n",
       "         ...,\n",
       "         [-0.1975972 ,  0.656217  , -1.5933743 , ...,  0.6431971 ,\n",
       "          -0.11670849,  1.057302  ],\n",
       "         [-0.19503179,  0.64633584, -1.5795717 , ...,  0.63758844,\n",
       "          -0.11323553,  1.0424476 ],\n",
       "         [-0.21782514,  0.669356  , -1.5617262 , ...,  0.66454303,\n",
       "          -0.1057626 ,  1.0601059 ]],\n",
       "\n",
       "        [[-0.21415013, -0.402642  , -0.30014685, ...,  0.7169521 ,\n",
       "          -0.9893657 , -0.94669956],\n",
       "         [-0.17885661, -0.4063309 , -0.3148486 , ...,  0.72428256,\n",
       "          -1.0130957 , -0.9592119 ],\n",
       "         [-0.19976029, -0.4110861 , -0.2952766 , ...,  0.7031219 ,\n",
       "          -0.9819925 , -0.9511016 ],\n",
       "         ...,\n",
       "         [-0.17689812, -0.41133958, -0.3159876 , ...,  0.70296925,\n",
       "          -1.0097198 , -0.95884913],\n",
       "         [-0.18196326, -0.4267295 , -0.2990716 , ...,  0.6834447 ,\n",
       "          -1.0086067 , -0.9459119 ],\n",
       "         [-0.16541004, -0.43584222, -0.32019842, ...,  0.713148  ,\n",
       "          -1.0005739 , -0.9428356 ]],\n",
       "\n",
       "        [[-0.38921916, -2.8171163 ,  0.8715481 , ...,  0.28652722,\n",
       "           0.56843936, -1.5085071 ],\n",
       "         [-0.3966946 , -2.7798007 ,  0.92609245, ...,  0.29132536,\n",
       "           0.54680526, -1.5083385 ],\n",
       "         [-0.39384985, -2.8019547 ,  0.9026555 , ...,  0.32035726,\n",
       "           0.55574083, -1.500983  ],\n",
       "         ...,\n",
       "         [-0.41041923, -2.799812  ,  0.9308742 , ...,  0.3247765 ,\n",
       "           0.55335087, -1.5207424 ],\n",
       "         [-0.39453247, -2.7671835 ,  0.91786444, ...,  0.31430003,\n",
       "           0.53593445, -1.5291126 ],\n",
       "         [-0.3974583 , -2.7985005 ,  0.909852  , ...,  0.34519204,\n",
       "           0.5655047 , -1.5235618 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.70113957,  0.47317022,  0.8360859 , ...,  2.7784584 ,\n",
       "          -0.86585057,  0.61919886],\n",
       "         [-0.6559127 ,  0.44089842,  0.88820565, ...,  2.7620263 ,\n",
       "          -0.89521813,  0.6486009 ],\n",
       "         [-0.70935714,  0.4415875 ,  0.85891664, ...,  2.786234  ,\n",
       "          -0.9012501 ,  0.6420575 ],\n",
       "         ...,\n",
       "         [-0.686229  ,  0.46789613,  0.85091853, ...,  2.7764924 ,\n",
       "          -0.902521  ,  0.69210696],\n",
       "         [-0.694619  ,  0.46165425,  0.8344315 , ...,  2.767227  ,\n",
       "          -0.89115465,  0.6667011 ],\n",
       "         [-0.6776539 ,  0.44920772,  0.8174974 , ...,  2.773806  ,\n",
       "          -0.8993559 ,  0.6633127 ]],\n",
       "\n",
       "        [[-1.6541721 ,  0.31528282,  0.9891999 , ...,  0.9107817 ,\n",
       "          -1.2034622 ,  0.6178112 ],\n",
       "         [-1.6256986 ,  0.32795876,  1.0075222 , ...,  0.94757473,\n",
       "          -1.1893089 ,  0.6500147 ],\n",
       "         [-1.6314998 ,  0.33384228,  1.0130506 , ...,  0.94010067,\n",
       "          -1.2186496 ,  0.64100873],\n",
       "         ...,\n",
       "         [-1.636525  ,  0.3316983 ,  1.0650194 , ...,  0.9281528 ,\n",
       "          -1.2175765 ,  0.66444474],\n",
       "         [-1.6320148 ,  0.3506536 ,  1.0555961 , ...,  0.93014044,\n",
       "          -1.2190835 ,  0.6571683 ],\n",
       "         [-1.6512942 ,  0.3232991 ,  1.0622435 , ...,  0.9483646 ,\n",
       "          -1.2053697 ,  0.6631834 ]],\n",
       "\n",
       "        [[ 0.7860085 , -0.5138855 , -2.302485  , ...,  0.3099578 ,\n",
       "           0.65321136, -0.6805129 ],\n",
       "         [ 0.7724472 , -0.46516958, -2.3250833 , ...,  0.33075398,\n",
       "           0.6657797 , -0.640321  ],\n",
       "         [ 0.77167606, -0.47520438, -2.2938685 , ...,  0.3314895 ,\n",
       "           0.68169665, -0.6803904 ],\n",
       "         ...,\n",
       "         [ 0.75867283, -0.50255346, -2.3124008 , ...,  0.30476224,\n",
       "           0.68978953, -0.6774199 ],\n",
       "         [ 0.76001334, -0.4966882 , -2.2774668 , ...,  0.30284268,\n",
       "           0.70390815, -0.65173054],\n",
       "         [ 0.78804636, -0.50151014, -2.2952063 , ...,  0.3150918 ,\n",
       "           0.68137586, -0.66081613]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-0.0702877 ,  0.34295928,  1.3765329 , ..., -2.863269  ,\n",
       "           0.95421624,  0.04243177],\n",
       "         [-0.06963481,  0.3591807 ,  1.3724802 , ..., -2.809072  ,\n",
       "           0.9282384 ,  0.02053964],\n",
       "         [-0.07584336,  0.34593892,  1.3595908 , ..., -2.8299952 ,\n",
       "           0.96734923, -0.00422603],\n",
       "         ...,\n",
       "         [-0.07962438,  0.36706156,  1.4167691 , ..., -2.8237805 ,\n",
       "           0.95750606,  0.00587821],\n",
       "         [-0.07256371,  0.33958787,  1.3947101 , ..., -2.8297765 ,\n",
       "           0.97006774, -0.0073849 ],\n",
       "         [-0.07803886,  0.34955835,  1.3821571 , ..., -2.809548  ,\n",
       "           0.963733  , -0.02551895]],\n",
       "\n",
       "        [[ 0.31723386,  0.26947176, -1.4790106 , ...,  0.20040664,\n",
       "          -0.1750847 , -0.49755406],\n",
       "         [ 0.33661115,  0.27321273, -1.4993054 , ...,  0.16153815,\n",
       "          -0.14753799, -0.48936543],\n",
       "         [ 0.34729752,  0.26316625, -1.478201  , ...,  0.1932041 ,\n",
       "          -0.15715411, -0.502827  ],\n",
       "         ...,\n",
       "         [ 0.37520152,  0.24616465, -1.447185  , ...,  0.17894076,\n",
       "          -0.16875994, -0.5250442 ],\n",
       "         [ 0.3525196 ,  0.26097447, -1.4558457 , ...,  0.20999576,\n",
       "          -0.17450243, -0.49907774],\n",
       "         [ 0.3590929 ,  0.256292  , -1.4624269 , ...,  0.18767881,\n",
       "          -0.18950394, -0.5059424 ]],\n",
       "\n",
       "        [[ 0.45973077,  0.21111465,  0.36989707, ...,  2.610086  ,\n",
       "          -0.6375573 ,  0.4112992 ],\n",
       "         [ 0.4679291 ,  0.17258477,  0.34750167, ...,  2.5893085 ,\n",
       "          -0.66049504,  0.42980963],\n",
       "         [ 0.4443527 ,  0.16961622,  0.3547353 , ...,  2.5999672 ,\n",
       "          -0.6505408 ,  0.3714211 ],\n",
       "         ...,\n",
       "         [ 0.44005102,  0.17543161,  0.36721042, ...,  2.5946374 ,\n",
       "          -0.6094734 ,  0.34291115],\n",
       "         [ 0.43865728,  0.16911066,  0.3575883 , ...,  2.6082253 ,\n",
       "          -0.65729564,  0.35738865],\n",
       "         [ 0.4428978 ,  0.192644  ,  0.34023902, ...,  2.5655541 ,\n",
       "          -0.6557209 ,  0.35148275]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.558463  ,  0.4830451 ,  1.7404678 , ..., -0.21904705,\n",
       "          -0.21239227, -0.800465  ],\n",
       "         [ 2.6156182 ,  0.46061334,  1.7665315 , ..., -0.19225675,\n",
       "          -0.23853928, -0.7904948 ],\n",
       "         [ 2.605177  ,  0.489394  ,  1.7571975 , ..., -0.18029234,\n",
       "          -0.21672353, -0.77246565],\n",
       "         ...,\n",
       "         [ 2.617143  ,  0.5025786 ,  1.7728591 , ..., -0.2013078 ,\n",
       "          -0.22708958, -0.79116845],\n",
       "         [ 2.6288514 ,  0.49452987,  1.740206  , ..., -0.19317158,\n",
       "          -0.19629693, -0.78580797],\n",
       "         [ 2.5783432 ,  0.47381994,  1.7641549 , ..., -0.21349342,\n",
       "          -0.21927625, -0.77473444]],\n",
       "\n",
       "        [[ 0.30533087,  1.2220699 , -1.1617221 , ...,  0.9116681 ,\n",
       "           0.427047  , -0.19131248],\n",
       "         [ 0.2845869 ,  1.254914  , -1.199925  , ...,  0.90328413,\n",
       "           0.4075961 , -0.19104406],\n",
       "         [ 0.29663944,  1.2731485 , -1.1623858 , ...,  0.8932069 ,\n",
       "           0.42599744, -0.19076128],\n",
       "         ...,\n",
       "         [ 0.3421933 ,  1.234938  , -1.1959512 , ...,  0.93456537,\n",
       "           0.44838625, -0.18664515],\n",
       "         [ 0.32213944,  1.2494366 , -1.1725358 , ...,  0.91662073,\n",
       "           0.43750924, -0.19092755],\n",
       "         [ 0.34071213,  1.2408917 , -1.1964192 , ...,  0.8726387 ,\n",
       "           0.42448008, -0.1567183 ]],\n",
       "\n",
       "        [[ 1.5897067 ,  0.01983309,  0.08103043, ..., -0.11160257,\n",
       "          -0.7640607 ,  1.5291841 ],\n",
       "         [ 1.6150355 ,  0.02981386,  0.09191024, ..., -0.08395776,\n",
       "          -0.76427084,  1.498147  ],\n",
       "         [ 1.5737554 ,  0.02270973,  0.08010146, ..., -0.11480652,\n",
       "          -0.74329066,  1.5021828 ],\n",
       "         ...,\n",
       "         [ 1.6364813 ,  0.05699226,  0.09352317, ..., -0.11598836,\n",
       "          -0.764487  ,  1.4878623 ],\n",
       "         [ 1.6332638 ,  0.08599338,  0.11617088, ..., -0.12324235,\n",
       "          -0.7549924 ,  1.4880717 ],\n",
       "         [ 1.6168735 ,  0.09900695,  0.08565655, ..., -0.12899795,\n",
       "          -0.744881  ,  1.5165727 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.45454162, -0.17427784, -1.6910286 , ..., -0.76568305,\n",
       "           1.0233794 ,  0.9069633 ],\n",
       "         [ 0.45186892, -0.15591854, -1.6976008 , ..., -0.78134644,\n",
       "           1.0419517 ,  0.9110966 ],\n",
       "         [ 0.4400815 , -0.15488762, -1.6939101 , ..., -0.7806582 ,\n",
       "           0.98163736,  0.9060001 ],\n",
       "         ...,\n",
       "         [ 0.4069564 , -0.17038321, -1.7342124 , ..., -0.7481609 ,\n",
       "           0.9628556 ,  0.91203076],\n",
       "         [ 0.43581575, -0.17508194, -1.7149082 , ..., -0.76247096,\n",
       "           1.0039909 ,  0.89311576],\n",
       "         [ 0.43808532, -0.13624306, -1.6863229 , ..., -0.7590297 ,\n",
       "           0.9806841 ,  0.89249444]],\n",
       "\n",
       "        [[-0.58357036, -1.3105423 ,  0.27985087, ..., -0.8793984 ,\n",
       "           0.29640663,  0.53650504],\n",
       "         [-0.59060836, -1.3105036 ,  0.33636525, ..., -0.8706247 ,\n",
       "           0.28902155,  0.5207227 ],\n",
       "         [-0.5824862 , -1.3372233 ,  0.2972517 , ..., -0.8732058 ,\n",
       "           0.3252303 ,  0.5211661 ],\n",
       "         ...,\n",
       "         [-0.5945052 , -1.3126644 ,  0.28220606, ..., -0.8743709 ,\n",
       "           0.3608486 ,  0.4984016 ],\n",
       "         [-0.5649758 , -1.2925386 ,  0.32195383, ..., -0.8620668 ,\n",
       "           0.34291545,  0.49994168],\n",
       "         [-0.55828345, -1.3190353 ,  0.30219635, ..., -0.8788169 ,\n",
       "           0.33854932,  0.5187224 ]],\n",
       "\n",
       "        [[ 0.4652233 ,  1.0748459 ,  0.33919978, ..., -1.1465404 ,\n",
       "          -0.4746681 , -0.6536321 ],\n",
       "         [ 0.46163923,  1.1051949 ,  0.3342818 , ..., -1.1596668 ,\n",
       "          -0.512791  , -0.67457306],\n",
       "         [ 0.4780513 ,  1.0733575 ,  0.3991064 , ..., -1.1751851 ,\n",
       "          -0.51898086, -0.6717774 ],\n",
       "         ...,\n",
       "         [ 0.47748923,  1.0782168 ,  0.36757398, ..., -1.1292974 ,\n",
       "          -0.50156355, -0.69543356],\n",
       "         [ 0.48639923,  1.0632648 ,  0.35406065, ..., -1.1687691 ,\n",
       "          -0.46690357, -0.6686777 ],\n",
       "         [ 0.4728466 ,  1.0801965 ,  0.33396593, ..., -1.1293237 ,\n",
       "          -0.494303  , -0.6651344 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3135653 , -0.3520539 , -0.3381929 , ...,  0.22258441,\n",
       "           0.08151376, -0.16336095],\n",
       "         [-1.3007052 , -0.3344011 , -0.32712784, ...,  0.23721784,\n",
       "           0.07751703, -0.169581  ],\n",
       "         [-1.3078854 , -0.37446925, -0.32061458, ...,  0.22491336,\n",
       "           0.0618059 , -0.18173641],\n",
       "         ...,\n",
       "         [-1.3281615 , -0.36374584, -0.32831147, ...,  0.24662897,\n",
       "           0.08405852, -0.1764692 ],\n",
       "         [-1.3739892 , -0.35190755, -0.3391359 , ...,  0.2608679 ,\n",
       "           0.04029006, -0.13708818],\n",
       "         [-1.3450474 , -0.35115418, -0.34650648, ...,  0.24788523,\n",
       "           0.09515631, -0.19753242]],\n",
       "\n",
       "        [[ 0.44288617, -0.98759025, -1.7112489 , ...,  0.06940186,\n",
       "          -2.2386475 ,  0.35772744],\n",
       "         [ 0.46282464, -0.9725112 , -1.7124909 , ...,  0.07058418,\n",
       "          -2.263383  ,  0.32968026],\n",
       "         [ 0.47749567, -0.9784713 , -1.6940395 , ...,  0.11885047,\n",
       "          -2.263411  ,  0.36065716],\n",
       "         ...,\n",
       "         [ 0.42801738, -0.9624009 , -1.6746066 , ...,  0.0921042 ,\n",
       "          -2.2503173 ,  0.34321398],\n",
       "         [ 0.42942262, -0.96093225, -1.7132803 , ...,  0.09077805,\n",
       "          -2.2107713 ,  0.34603018],\n",
       "         [ 0.45645303, -0.9735998 , -1.7204514 , ...,  0.0899778 ,\n",
       "          -2.2460797 ,  0.35353935]],\n",
       "\n",
       "        [[ 0.18495163, -0.6563165 ,  0.3429759 , ...,  1.1129708 ,\n",
       "          -0.03793067, -1.1061329 ],\n",
       "         [ 0.1940625 , -0.6640722 ,  0.33438712, ...,  1.1214477 ,\n",
       "          -0.03415221, -1.1122845 ],\n",
       "         [ 0.2245718 , -0.69015133,  0.38030893, ...,  1.1349868 ,\n",
       "          -0.02044344, -1.1341441 ],\n",
       "         ...,\n",
       "         [ 0.21003214, -0.6679464 ,  0.37342304, ...,  1.1282136 ,\n",
       "          -0.05360895, -1.1054654 ],\n",
       "         [ 0.19655308, -0.68355364,  0.3528071 , ...,  1.1191945 ,\n",
       "           0.01993281, -1.1059006 ],\n",
       "         [ 0.17165627, -0.6780883 ,  0.36320978, ...,  1.1437752 ,\n",
       "           0.01150876, -1.1089634 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8, 101, 64), dtype=float32, numpy=\n",
       "array([[[[-1.6979020e+00,  2.4518654e-01,  1.1335567e+00, ...,\n",
       "           5.7901764e-01,  4.1754189e-01,  5.7246971e-01],\n",
       "         [-1.7264888e+00,  2.0185724e-01,  1.1295152e+00, ...,\n",
       "           6.0476303e-01,  4.0357435e-01,  5.5714226e-01],\n",
       "         [-1.7297066e+00,  1.9622424e-01,  1.1516566e+00, ...,\n",
       "           5.9404945e-01,  4.2103979e-01,  5.4676419e-01],\n",
       "         ...,\n",
       "         [-1.6989619e+00,  1.9519445e-01,  1.1721702e+00, ...,\n",
       "           5.7640517e-01,  3.9942479e-01,  5.4298568e-01],\n",
       "         [-1.7520626e+00,  1.9360857e-01,  1.1594346e+00, ...,\n",
       "           5.7880718e-01,  4.2705336e-01,  5.5310571e-01],\n",
       "         [-1.7008756e+00,  1.9558838e-01,  1.1695480e+00, ...,\n",
       "           5.5096900e-01,  3.8781577e-01,  5.5450749e-01]],\n",
       "\n",
       "        [[ 9.1355276e-01,  1.0379161e+00, -1.2667453e-01, ...,\n",
       "           1.6996920e-02, -6.8886453e-01,  1.3074574e+00],\n",
       "         [ 8.8603169e-01,  1.0723221e+00, -9.3724459e-02, ...,\n",
       "           1.4791429e-02, -6.8802989e-01,  1.2698486e+00],\n",
       "         [ 8.8194036e-01,  1.0321991e+00, -1.3197616e-01, ...,\n",
       "           3.4623891e-02, -7.1162665e-01,  1.3015273e+00],\n",
       "         ...,\n",
       "         [ 8.5916340e-01,  1.0150403e+00, -1.1038980e-01, ...,\n",
       "           5.3052366e-02, -6.9952780e-01,  1.3293998e+00],\n",
       "         [ 9.0438211e-01,  1.0642235e+00, -1.2624368e-01, ...,\n",
       "           3.7148833e-02, -7.0820391e-01,  1.3192739e+00],\n",
       "         [ 8.7515354e-01,  1.0439919e+00, -1.2129250e-01, ...,\n",
       "           5.3023547e-02, -6.8093830e-01,  1.2812698e+00]],\n",
       "\n",
       "        [[ 1.5221112e+00,  2.4484484e-01,  4.9573123e-02, ...,\n",
       "          -4.2783612e-01,  3.4589589e-02, -1.5454535e+00],\n",
       "         [ 1.4933250e+00,  2.0592113e-01,  2.7992129e-03, ...,\n",
       "          -4.0615246e-01,  5.9389412e-02, -1.5449467e+00],\n",
       "         [ 1.4814436e+00,  2.6698986e-01,  6.6554487e-02, ...,\n",
       "          -4.1866300e-01,  9.0357482e-02, -1.5255213e+00],\n",
       "         ...,\n",
       "         [ 1.4910268e+00,  2.4610752e-01,  1.0786158e-01, ...,\n",
       "          -4.1854087e-01,  8.5461378e-02, -1.5354801e+00],\n",
       "         [ 1.5134345e+00,  2.4158187e-01,  8.7416947e-02, ...,\n",
       "          -4.4449148e-01,  8.1766427e-02, -1.5440831e+00],\n",
       "         [ 1.4687997e+00,  2.3988111e-01,  8.4353268e-02, ...,\n",
       "          -4.1062379e-01,  5.3319573e-02, -1.5362902e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6918993e-01,  1.0907665e+00, -5.2206796e-01, ...,\n",
       "          -1.5066669e+00, -2.4434145e-01,  1.2925566e+00],\n",
       "         [-2.1522409e-01,  1.1156240e+00, -4.9046183e-01, ...,\n",
       "          -1.5308332e+00, -2.2127511e-01,  1.3090194e+00],\n",
       "         [-1.5528512e-01,  1.0971879e+00, -5.2816606e-01, ...,\n",
       "          -1.5085360e+00, -2.2818503e-01,  1.3005230e+00],\n",
       "         ...,\n",
       "         [-2.0560372e-01,  1.0407623e+00, -5.0785893e-01, ...,\n",
       "          -1.4920846e+00, -2.5092095e-01,  1.3329456e+00],\n",
       "         [-1.7302704e-01,  1.0892704e+00, -4.9707133e-01, ...,\n",
       "          -1.4658550e+00, -2.0925157e-01,  1.3276021e+00],\n",
       "         [-1.8199468e-01,  1.0966415e+00, -5.1505184e-01, ...,\n",
       "          -1.5111959e+00, -2.0768212e-01,  1.3401949e+00]],\n",
       "\n",
       "        [[ 8.4110081e-01,  3.3919770e-01, -3.2212088e+00, ...,\n",
       "          -1.4925773e+00,  6.9762677e-02,  1.2455318e+00],\n",
       "         [ 8.3327854e-01,  3.5846251e-01, -3.1966376e+00, ...,\n",
       "          -1.4479942e+00,  1.4394802e-01,  1.2698977e+00],\n",
       "         [ 8.6795557e-01,  3.8189518e-01, -3.2245355e+00, ...,\n",
       "          -1.4914383e+00,  1.1431247e-01,  1.2317779e+00],\n",
       "         ...,\n",
       "         [ 8.6150885e-01,  3.4370667e-01, -3.2485492e+00, ...,\n",
       "          -1.5034581e+00,  8.1657618e-02,  1.2149065e+00],\n",
       "         [ 8.3168781e-01,  3.4647694e-01, -3.1595960e+00, ...,\n",
       "          -1.5003145e+00,  1.1299783e-01,  1.2263404e+00],\n",
       "         [ 8.6194396e-01,  3.5434887e-01, -3.2090132e+00, ...,\n",
       "          -1.5015433e+00,  9.7510695e-02,  1.2173362e+00]],\n",
       "\n",
       "        [[-3.9493981e-01,  6.8499136e-01,  8.5763299e-01, ...,\n",
       "           8.6783582e-01,  1.8373685e+00, -2.9115009e-01],\n",
       "         [-3.7519073e-01,  7.1775466e-01,  8.3976853e-01, ...,\n",
       "           8.6015379e-01,  1.8096675e+00, -3.1674170e-01],\n",
       "         [-3.6313403e-01,  6.7533267e-01,  8.2593894e-01, ...,\n",
       "           8.9115411e-01,  1.8354747e+00, -3.1813455e-01],\n",
       "         ...,\n",
       "         [-4.2152801e-01,  6.8642217e-01,  8.3812827e-01, ...,\n",
       "           8.7181783e-01,  1.7988318e+00, -2.8822368e-01],\n",
       "         [-3.9494136e-01,  6.7391312e-01,  8.4505707e-01, ...,\n",
       "           8.4752822e-01,  1.8587527e+00, -3.0245292e-01],\n",
       "         [-4.3165267e-01,  6.8043387e-01,  8.5852784e-01, ...,\n",
       "           8.6518198e-01,  1.8357611e+00, -3.3845407e-01]]]],\n",
       "      dtype=float32)>)), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=<tf.Tensor: shape=(1, 101, 512), dtype=float32, numpy=\n",
       "array([[[ 0.48820046,  1.8285493 ,  0.5921232 , ...,  1.3295274 ,\n",
       "         -1.148115  ,  0.70029473],\n",
       "        [ 0.467287  ,  1.8568046 ,  0.56075126, ...,  1.3551215 ,\n",
       "         -1.153077  ,  0.6729566 ],\n",
       "        [ 0.44393867,  1.8147483 ,  0.559446  , ...,  1.3675531 ,\n",
       "         -1.1334672 ,  0.68404007],\n",
       "        ...,\n",
       "        [ 0.4381299 ,  1.7840797 ,  0.5516232 , ...,  1.3632866 ,\n",
       "         -1.141668  ,  0.71430963],\n",
       "        [ 0.45610204,  1.8290333 ,  0.58786494, ...,  1.3675493 ,\n",
       "         -1.1359842 ,  0.6885297 ],\n",
       "        [ 0.44670087,  1.8239667 ,  0.5919506 , ...,  1.3203855 ,\n",
       "         -1.096112  ,  0.689557  ]]], dtype=float32)>, encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoder_input_ids should be tokenized input ids of summary\n",
    "output = model_without_head(inputs.input_ids, decoder_input_ids=inputs.input_ids, return_dict=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80e6b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       "array([[-4.62765425e-01,  1.09592676e+00,  1.02431762e+00,\n",
       "        -8.61518919e-01,  3.01193267e-01, -4.57092613e-01,\n",
       "         4.04883653e-01,  1.63444293e+00,  1.41569674e-01,\n",
       "        -1.80862434e-02,  7.85361111e-01, -1.26193881e+00,\n",
       "         1.41255713e+00, -7.88933933e-01,  4.29367214e-01,\n",
       "         1.48956284e-01,  1.18693542e+00, -1.07305080e-01,\n",
       "        -4.79683399e-01, -3.45987558e-01, -7.54406571e-01,\n",
       "         7.18635321e-01,  7.34846413e-01,  1.04856646e+00,\n",
       "         8.97109747e-01,  6.79533064e-01, -1.21847844e+00,\n",
       "         9.55356181e-01,  1.27251789e-01, -1.45679367e+00,\n",
       "        -2.14301810e-01,  1.42446673e+00, -8.95364225e-01,\n",
       "         2.72548199e-01,  6.73023999e-01,  7.32028544e-01,\n",
       "         2.12593651e+00,  1.57341826e+00, -6.84934914e-01,\n",
       "        -1.95827281e+00,  8.12734306e-01,  4.32506680e-01,\n",
       "         1.16787004e+00,  5.57159185e-01,  3.39249402e-01,\n",
       "         1.93310523e+00,  7.38496780e-01, -1.02255034e+00,\n",
       "        -3.28741074e-01,  8.16722035e-01, -3.49912159e-02,\n",
       "        -1.75510809e-01,  1.21961914e-01, -7.20564425e-01,\n",
       "         7.06043005e-01,  1.01356912e+00, -1.29344714e+00,\n",
       "        -4.34573501e-01,  2.43745282e-01,  1.50246549e+00,\n",
       "        -8.54493976e-01,  1.49495915e-01, -8.31459761e-01,\n",
       "         5.60275435e-01, -5.47161758e-01, -7.93467760e-01,\n",
       "        -1.52518988e-01,  2.61413789e+00,  2.84962896e-02,\n",
       "         6.36127830e-01,  1.51092625e+00,  9.09968376e-01,\n",
       "        -8.46624970e-01,  2.39434052e+00,  1.56672692e+00,\n",
       "         3.96770030e-01, -7.01298475e-01, -3.67326736e-02,\n",
       "        -9.43008065e-01, -6.84428692e-01, -2.18167886e-01,\n",
       "         2.99631447e-01, -4.96770591e-01,  4.15637009e-02,\n",
       "         9.12022471e-01,  7.07549870e-01,  1.85524464e-01,\n",
       "         9.92428124e-01,  3.04207087e-01,  7.04987347e-01,\n",
       "         1.39445558e-01,  8.22775781e-01,  6.01436384e-02,\n",
       "         1.06106138e+00,  2.47376037e+00,  1.32989454e+00,\n",
       "         2.74928737e+00,  4.42891985e-01,  9.29570198e-01,\n",
       "         1.22164822e+00,  1.54880202e+00, -6.49327219e-01,\n",
       "        -1.24722488e-01, -7.28941441e-01, -3.54922824e-02,\n",
       "        -1.44553453e-01, -4.12298828e-01,  1.29950917e+00,\n",
       "         6.35526955e-01,  8.54785383e-01,  8.90421718e-02,\n",
       "        -3.49400312e-01,  7.64203429e-01, -1.39496744e-01,\n",
       "        -1.86598337e+00,  8.08830678e-01, -1.30070782e+00,\n",
       "        -6.30998552e-01, -3.09000283e-01, -2.39804000e-01,\n",
       "        -2.10103258e-01,  3.12387824e-01,  1.26964664e+00,\n",
       "         1.52097631e+00,  7.87762403e-01,  7.77311862e-01,\n",
       "         1.66995037e+00,  5.00881612e-01, -6.35969818e-01,\n",
       "        -5.26024222e-01, -7.87501991e-01,  1.30424130e+00,\n",
       "         5.17887235e-01,  1.76265255e-01,  3.15341987e-02,\n",
       "        -9.19274986e-01,  7.40311593e-02,  1.07430232e+00,\n",
       "        -9.24786776e-02,  1.51942825e+00,  4.92144525e-02,\n",
       "        -8.25219154e-01, -5.45021594e-01,  9.91143048e-01,\n",
       "         6.91944301e-01,  9.58320260e-01,  1.24191654e+00,\n",
       "         2.58828431e-01, -4.99754548e-01, -1.12193041e-01,\n",
       "        -9.46648717e-01,  1.14420259e+00,  6.66621923e-01,\n",
       "        -8.12277734e-01, -1.11062324e+00, -1.14804554e+00,\n",
       "         1.03665137e+00, -9.06579912e-01,  6.64957464e-01,\n",
       "         9.45820007e-03, -1.23717380e+00,  3.80461186e-01,\n",
       "        -6.14617288e-01,  1.13656521e+00,  3.78059834e-01,\n",
       "        -6.43576503e-01,  4.41683173e-01,  2.22054410e+00,\n",
       "         8.73247325e-01,  1.70385504e+00,  3.60054940e-01,\n",
       "        -1.25844121e-01,  7.09426820e-01, -6.03216708e-01,\n",
       "        -1.54765379e+00,  1.36475563e-01, -2.09673747e-01,\n",
       "         8.31280351e-01, -5.28152764e-01, -4.65054542e-01,\n",
       "         1.26874015e-01,  3.70225221e-01,  1.77648211e+00,\n",
       "        -6.68647230e-01, -1.22360036e-01,  7.62234211e-01,\n",
       "         7.01601207e-02,  9.63001549e-01,  5.94632089e-01,\n",
       "         1.20421815e+00, -7.98929989e-01, -1.34813988e+00,\n",
       "        -8.51423264e-01,  1.07433903e+00, -2.22321060e-02,\n",
       "        -1.90571100e-01, -1.99129009e+00,  5.38005531e-01,\n",
       "         1.03511274e+00,  1.23446546e-01,  1.81201172e+00,\n",
       "        -7.48771250e-01,  1.26477766e+00,  1.49163723e-01,\n",
       "         7.84064293e-01,  1.43031347e+00,  1.61298513e+00,\n",
       "         1.37540370e-01,  1.02638566e+00, -4.63326186e-01,\n",
       "        -2.07643318e+00,  1.55062354e+00,  1.95262682e+00,\n",
       "         1.16608009e-01,  1.81172848e+00,  1.63701582e+00,\n",
       "        -8.01023722e-01,  1.35044956e+00, -9.29434001e-01,\n",
       "        -6.62905931e-01,  1.17928565e+00, -1.24961567e+00,\n",
       "         9.21274900e-01, -3.07638466e-01, -4.03587878e-01,\n",
       "         2.05614328e+00,  5.22106420e-03,  1.84867811e+00,\n",
       "         3.77728969e-01,  1.59979737e+00, -1.98523498e+00,\n",
       "        -2.85867393e-01, -2.86838889e-01,  1.21282446e+00,\n",
       "         8.15010190e-01,  9.77722883e-01, -7.59150922e-01,\n",
       "         5.88956952e-01,  1.15192533e+00, -8.07837248e-02,\n",
       "         5.72993100e-01,  1.79174364e-01,  9.79454100e-01,\n",
       "         1.84885907e+00, -4.03303236e-01, -1.05206561e+00,\n",
       "         5.50646782e-01,  2.77533650e-01,  3.50138158e-01,\n",
       "        -8.07301223e-01,  1.83761418e+00, -1.36927330e+00,\n",
       "         1.26002765e+00,  9.24581528e-01, -5.64270854e-01,\n",
       "         1.44132483e+00,  3.67971897e-01,  1.33849728e+00,\n",
       "         1.11439741e+00,  2.03208312e-01,  1.78394032e+00,\n",
       "        -1.02549046e-02,  2.64032871e-01,  1.60408354e+00,\n",
       "         2.62034565e-01, -1.25385261e+00,  1.31121039e+00,\n",
       "        -9.86044049e-01, -4.06176239e-01,  1.05173755e+00,\n",
       "         6.18621297e-02,  2.58177924e+00,  5.73202968e-01,\n",
       "        -1.00009596e+00, -1.54147851e+00, -8.69290113e-01,\n",
       "         3.75939049e-02, -1.07379310e-01,  3.90963197e-01,\n",
       "         1.43620181e+00,  2.12868571e+00,  5.06856665e-02,\n",
       "         4.78208095e-01,  2.16651365e-01,  1.11098051e+00,\n",
       "         1.44940650e+00,  5.91957569e-01,  1.42230678e+00,\n",
       "        -2.38520920e-01,  5.02498925e-01,  2.14216143e-01,\n",
       "         6.49827242e-01,  1.37276852e+00,  4.97550935e-01,\n",
       "        -3.40361297e-02,  1.09213448e+00,  1.05516657e-01,\n",
       "         2.72613108e-01,  9.82652605e-01, -1.13271582e+00,\n",
       "         7.62159705e-01,  4.59009200e-01, -5.69378793e-01,\n",
       "         1.14762104e+00,  1.32018745e+00,  1.29834020e+00,\n",
       "         6.21638417e-01, -1.27732825e+00,  8.64280581e-01,\n",
       "         1.69909880e-01,  9.75133061e-01, -2.85696596e-01,\n",
       "         1.74992359e+00, -3.82763505e-01, -6.72685325e-01,\n",
       "         7.12561905e-01,  1.09611559e+00,  1.32807577e+00,\n",
       "         5.00247240e-01, -6.46584511e-01, -6.91080511e-01,\n",
       "         1.14426613e+00,  3.69341016e-01, -2.07762051e+00,\n",
       "         4.72584245e-04,  5.46440005e-01, -3.36935014e-01,\n",
       "        -2.78403908e-01,  1.45985770e+00, -7.85718679e-01,\n",
       "         1.10580671e+00, -9.63021636e-01, -1.85137820e+00,\n",
       "         2.44123340e-01, -1.31733251e+00,  1.92478418e+00,\n",
       "         1.32595289e+00, -1.51516870e-01,  2.29594064e+00,\n",
       "         1.18029930e-01, -1.29184103e+00,  2.03625396e-01,\n",
       "         7.79332161e-01, -1.39792442e-01,  1.28320551e+00,\n",
       "         1.81496882e+00, -5.44077992e-01, -1.14070070e+00,\n",
       "         4.11752582e-01,  4.56274301e-01,  2.20009446e+00,\n",
       "         5.98073937e-02,  4.48636770e-01, -2.14431971e-01,\n",
       "         6.08114123e-01, -6.18652254e-02,  1.59280992e+00,\n",
       "         7.17807949e-01,  2.22328234e+00,  1.91488504e-01,\n",
       "         1.98537186e-01, -1.31269276e+00, -4.06114846e-01,\n",
       "         3.17693204e-01,  1.50080264e-01,  2.82865763e+00,\n",
       "        -5.93382716e-01,  2.84722596e-01,  3.43532681e-01,\n",
       "         6.75358891e-01,  7.69071102e-01,  2.31547579e-01,\n",
       "         1.50242639e+00, -2.99014390e-01,  5.18930912e-01,\n",
       "        -2.28271812e-01,  4.20238912e-01,  1.99148726e+00,\n",
       "        -1.04841590e+00,  2.95855701e-01, -2.16993585e-01,\n",
       "         1.02102530e+00,  1.18007600e+00,  1.62172109e-01,\n",
       "        -1.29474843e+00,  5.35027266e-01, -5.30538261e-02,\n",
       "        -2.16700241e-01,  2.41510004e-01,  8.21552873e-01,\n",
       "         1.50914931e+00, -2.00651109e-01,  2.97112167e-01,\n",
       "         1.74846327e+00,  2.86898851e-01,  4.85758223e-02,\n",
       "         7.13813245e-01, -7.86632121e-01,  6.65724695e-01,\n",
       "        -1.66705668e+00, -1.18845113e-01,  1.07132936e+00,\n",
       "        -1.15470326e+00,  8.00890267e-01,  3.65559280e-01,\n",
       "         1.21576798e+00, -5.76523542e-01,  6.29758358e-01,\n",
       "        -6.32942140e-01,  1.17995310e+00,  4.05334622e-01,\n",
       "         1.83237696e+00, -7.09010601e-01,  1.87975061e+00,\n",
       "         4.86480176e-01,  1.40387286e-02,  1.15775859e+00,\n",
       "         1.91693807e+00,  1.32649079e-01,  4.71606791e-01,\n",
       "         5.20438254e-01,  1.34995669e-01, -1.35284269e+00,\n",
       "        -1.92986202e+00,  8.16212520e-02, -7.73337305e-01,\n",
       "         9.63094473e-01,  1.76184380e+00, -4.53936934e-01,\n",
       "         3.59270096e-01,  7.93602586e-01, -5.52835941e-01,\n",
       "        -1.09967425e-01,  2.28370562e-01, -3.84923011e-01,\n",
       "         1.03955650e+00, -4.05249685e-01, -3.54466468e-01,\n",
       "         6.42986536e-01,  9.59093630e-01,  1.01127493e+00,\n",
       "         1.54622054e+00,  8.94863665e-01, -8.89212906e-01,\n",
       "         6.47839248e-01,  1.31861591e+00,  7.83152997e-01,\n",
       "        -3.22815776e-01, -2.92982876e-01,  4.43031967e-01,\n",
       "         6.98231936e-01,  3.68104517e-01,  1.07007396e+00,\n",
       "        -2.40459099e-01, -7.34500028e-03,  2.15889633e-01,\n",
       "         2.07336283e+00,  2.11216196e-01,  2.75436497e+00,\n",
       "        -5.26165485e-01,  4.49565947e-01,  1.29222363e-01,\n",
       "         2.06266448e-01,  7.22712636e-01,  1.03401315e+00,\n",
       "        -5.04879475e-01, -2.20617037e-02, -1.61263227e+00,\n",
       "         8.95961106e-01, -1.51482010e+00, -5.31756103e-01,\n",
       "        -6.10928476e-01,  2.12205100e+00, -3.40811789e-01,\n",
       "         1.20351124e+00,  2.83248639e+00, -1.42369699e-02,\n",
       "        -6.86536312e-01,  3.76548588e-01, -3.35393608e-01,\n",
       "         1.13709664e+00,  1.09074152e+00,  1.41413307e+00,\n",
       "         3.60900313e-01,  8.82634699e-01,  8.94784689e-01,\n",
       "        -1.09354854e-01,  1.85729790e+00,  1.11628067e+00,\n",
       "         7.25714043e-02,  1.31942427e+00, -3.34948339e-02,\n",
       "        -8.32586527e-01, -9.51886594e-01,  1.52508274e-01,\n",
       "        -9.90682654e-03, -1.26996398e+00,  6.71629488e-01,\n",
       "         8.48505378e-01,  3.25747252e-01, -8.81678835e-02,\n",
       "         1.62318933e+00, -3.60044152e-01,  3.99097353e-01,\n",
       "         2.37272352e-01,  1.90656817e+00,  8.94996345e-01,\n",
       "        -6.85091257e-01, -2.23108202e-01,  2.62080336e+00,\n",
       "         1.53018403e+00, -8.62919018e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e90a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5RewardModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(T5RewardModel, self).__init__()\n",
    "        self.t5_without_lm_head = TFT5Model(config).from_pretrained(\"t5-small\")\n",
    "        self.reward_head = tf.keras.layers.Dense(1, use_bias=False, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, decoder_input_ids = inputs\n",
    "        sequence_output = self.t5_without_lm_head(\n",
    "            input_ids,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            training=training).last_hidden_state\n",
    "\n",
    "        reward_output = self.reward_head(sequence_output[:,0,:]) ## extract the 1st token's embeddings\n",
    "\n",
    "        return reward_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1092c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.8869067]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "reward_model = T5RewardModel()\n",
    "\n",
    "reward_model((inputs.input_ids, inputs.input_ids)) # (input token id, target token id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7abe8ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"t5_reward_model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tft5_model_23 (TFT5Model)   multiple                  60506624  \n",
      "                                                                 \n",
      " dense_20 (Dense)            multiple                  512       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,507,136\n",
      "Trainable params: 60,507,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reward_model.summaryr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "08d59686",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc54b55",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2cec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-146c1daaf6dd79a6\n",
      "Found cached dataset json (/home/ayushthakur/.cache/huggingface/datasets/json/default-146c1daaf6dd79a6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf11ef4681aa48e0a012869998cce9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8dfa26f346d28263\n",
      "Found cached dataset json (/home/ayushthakur/.cache/huggingface/datasets/json/default-8dfa26f346d28263/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6a0743cefb4cab93ab2889c48203ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = \"../../comparison_splits\"\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=f\"{DATA_PATH}/train.jsonl\")[\"train\"]\n",
    "valid_dataset = load_dataset(\"json\", data_files=f\"{DATA_PATH}/valid.jsonl\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04ab2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Previous: \\n\\nGuys, I think I\\'m \"cured\". It was a strange event but what the heck, it made me realize something.\\n\\nI was studying late at night in my room a few days ago. I have this shelf in my room with a bunch of zelda collectibles and a really expensive Zelda figurine underneath it ($400+).\\n\\nWell, guess what. As my luck would have it, Ikea shelf gave in, all my collectibles fell to the ground and the shelf knocked down my figure and destroyed it.\\n\\nObviously a distressing moment for me but it was also at that time I realised I needed to perhaps chill with this hobby and that the hobby can still be mine without having to necessarily share it with a significant other.\\n\\nOf course I would PREFER if she liked Zelda too and it would definitely be a huge plus in my book but if I fall in love with a girl who isn\\'t into Zelda, I guess that\\'s just how it\\'s going to be. I\\'m honestly not going to worry too much about this to be honest, I have enough on my plate with studies as it is. Plus I gotta take some extra shifts at work so I can replace my broken statue and collectibles. Unfortunately some of them can\\'t be bought anymore but oh well such is life.\\n\\nThanks everyone for reaching out to me and helping me. This has been an eye opener for me. I\\'m more than willing to date a girl who doesn\\'t care about Zelda because honestly, if she is just there for me and makes me happy, I feel that is all I could ask for. However if she happens to like Zelda too, then that\\'s great (not a requirement, just a plus!)\\n I have Zelda figurine and I need to find a girl to date that will also like Zelda but not be a huge fan of Zelda.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"post\"] + \"\\n\" + train_dataset[0][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dcf7e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"binary classification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a9aa5b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary classification: Previous: \\n\\nGuys, I think I\\'m \"cured\". It was a strange event but what the heck, it made me realize something.\\n\\nI was studying late at night in my room a few days ago. I have this shelf in my room with a bunch of zelda collectibles and a really expensive Zelda figurine underneath it ($400+).\\n\\nWell, guess what. As my luck would have it, Ikea shelf gave in, all my collectibles fell to the ground and the shelf knocked down my figure and destroyed it.\\n\\nObviously a distressing moment for me but it was also at that time I realised I needed to perhaps chill with this hobby and that the hobby can still be mine without having to necessarily share it with a significant other.\\n\\nOf course I would PREFER if she liked Zelda too and it would definitely be a huge plus in my book but if I fall in love with a girl who isn\\'t into Zelda, I guess that\\'s just how it\\'s going to be. I\\'m honestly not going to worry too much about this to be honest, I have enough on my plate with studies as it is. Plus I gotta take some extra shifts at work so I can replace my broken statue and collectibles. Unfortunately some of them can\\'t be bought anymore but oh well such is life.\\n\\nThanks everyone for reaching out to me and helping me. This has been an eye opener for me. I\\'m more than willing to date a girl who doesn\\'t care about Zelda because honestly, if she is just there for me and makes me happy, I feel that is all I could ask for. However if she happens to like Zelda too, then that\\'s great (not a requirement, just a plus!)\\n I have Zelda figurine and I need to find a girl to date that will also like Zelda but not be a huge fan of Zelda.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs1 = PREFIX + train_dataset[0][\"post\"] + \"\\n\" + train_dataset[0][\"summary\"]\n",
    "inputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f2bb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e940c80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 428), dtype=int32, numpy=\n",
       "array([[14865, 13774,    10, 10232,    10,  9070,     6,    27,   317,\n",
       "           27,    31,    51,    96, 26867,  1280,    94,    47,     3,\n",
       "            9,  6765,   605,    68,   125,     8, 24783,     6,    34,\n",
       "          263,   140,  3384,   424,     5,    27,    47,  6908,  1480,\n",
       "           44,   706,    16,    82,   562,     3,     9,   360,   477,\n",
       "          977,     5,    27,    43,    48,  8625,    16,    82,   562,\n",
       "           28,     3,     9,  7292,    13,     3,  4650,    26,     9,\n",
       "         2868,  2317,     7,    11,     3,     9,   310,  2881,  1027,\n",
       "         8804,     9, 31193, 13483,    34,  8785,  5548,  1220,   137,\n",
       "         1548,     6,  3382,   125,     5,   282,    82,  5851,   133,\n",
       "           43,    34,     6, 25907,  8625,  1891,    16,     6,    66,\n",
       "           82,  2868,  2317,     7,  4728,    12,     8,  1591,    11,\n",
       "            8,  8625,  7673,    15,    26,   323,    82,  2320,    11,\n",
       "        10932,    34,     5,     3, 14116,     3,     9, 19285,    53,\n",
       "          798,    21,   140,    68,    34,    47,    92,    44,    24,\n",
       "           97,    27,     3, 19007,    27,   906,    12,  2361, 10191,\n",
       "           28,    48, 14687,    11,    24,     8, 14687,    54,   341,\n",
       "           36,  2000,   406,   578,    12,  6539,   698,    34,    28,\n",
       "            3,     9,  1516,   119,     5,  1129,   503,    27,   133,\n",
       "        22694, 20805,     3,    99,   255,  6528,  1027,  8804,     9,\n",
       "          396,    11,    34,   133,  1728,    36,     3,     9,  1450,\n",
       "          303,    16,    82,   484,    68,     3,    99,    27,  1590,\n",
       "           16,   333,    28,     3,     9,  3202,   113,    19,    29,\n",
       "           31,    17,   139,  1027,  8804,     9,     6,    27,  3382,\n",
       "           24,    31,     7,   131,   149,    34,    31,     7,   352,\n",
       "           12,    36,     5,    27,    31,    51, 12855,    59,   352,\n",
       "           12,  3516,   396,   231,    81,    48,    12,    36,  5057,\n",
       "            6,    27,    43,   631,    30,    82,  3829,    28,  2116,\n",
       "           38,    34,    19,     5,  2477,    27,     3, 26761,   240,\n",
       "          128,   996,  4108,     7,    44,   161,    78,    27,    54,\n",
       "         3601,    82,  4335, 12647,    11,  2868,  2317,     7,     5,\n",
       "         4877,   128,    13,   135,    54,    31,    17,    36,  2944,\n",
       "         7595,    68,     3,    32,   107,   168,   224,    19,   280,\n",
       "            5,  1333,   921,    21,  7232,    91,    12,   140,    11,\n",
       "         2022,   140,     5,   100,    65,   118,    46,  1580, 19717,\n",
       "           21,   140,     5,    27,    31,    51,    72,   145,  4403,\n",
       "           12,   833,     3,     9,  3202,   113,   744,    31,    17,\n",
       "          124,    81,  1027,  8804,     9,   250, 12855,     6,     3,\n",
       "           99,   255,    19,   131,   132,    21,   140,    11,   656,\n",
       "          140,  1095,     6,    27,   473,    24,    19,    66,    27,\n",
       "          228,   987,    21,     5,   611,     3,    99,   255,  2906,\n",
       "           12,   114,  1027,  8804,     9,   396,     6,   258,    24,\n",
       "           31,     7,   248,    41,  2264,     3,     9,  5971,     6,\n",
       "          131,     3,     9,   303,  4819,    27,    43,  1027,  8804,\n",
       "            9, 31193,    11,    27,   174,    12,   253,     3,     9,\n",
       "         3202,    12,   833,    24,    56,    92,   114,  1027,  8804,\n",
       "            9,    68,    59,    36,     3,     9,  1450,  1819,    13,\n",
       "         1027,  8804,     9,     5,     1]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 428), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tokenizer(inputs1, return_tensors=\"tf\")\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "817e8696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binary classification: P',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification: v',\n",
       " 'binary classification: i',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: s',\n",
       " 'binary classification: :',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: G',\n",
       " 'binary classification: u',\n",
       " 'binary classification: y',\n",
       " 'binary classification: s',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: k',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " \"binary classification: '\",\n",
       " 'binary classification: m',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: \"',\n",
       " 'binary classification: c',\n",
       " 'binary classification: u',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification: \"',\n",
       " 'binary classification: .',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: a',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: r',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: e',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification: n',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: u',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification: c',\n",
       " 'binary classification: k',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: a',\n",
       " 'binary classification: d',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification: a',\n",
       " 'binary classification: l',\n",
       " 'binary classification: i',\n",
       " 'binary classification: z',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: o',\n",
       " 'binary classification: m',\n",
       " 'binary classification: e',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification: .',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: a',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: u',\n",
       " 'binary classification: d',\n",
       " 'binary classification: y',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: l',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: n',\n",
       " 'binary classification: i',\n",
       " 'binary classification: g',\n",
       " 'binary classification: h',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: r',\n",
       " 'binary classification: o',\n",
       " 'binary classification: o',\n",
       " 'binary classification: m',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: f',\n",
       " 'binary classification: e',\n",
       " 'binary classification: w',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: d',\n",
       " 'binary classification: a',\n",
       " 'binary classification: y',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: g',\n",
       " 'binary classification: o',\n",
       " 'binary classification: .',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: r',\n",
       " 'binary classification: o',\n",
       " 'binary classification: o',\n",
       " 'binary classification: m',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: u',\n",
       " 'binary classification: n',\n",
       " 'binary classification: c',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: o',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: z',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: c',\n",
       " 'binary classification: o',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification: e',\n",
       " 'binary classification: c',\n",
       " 'binary classification: t',\n",
       " 'binary classification: i',\n",
       " 'binary classification: b',\n",
       " 'binary classification: l',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification: a',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: e',\n",
       " 'binary classification: x',\n",
       " 'binary classification: p',\n",
       " 'binary classification: e',\n",
       " 'binary classification: n',\n",
       " 'binary classification: s',\n",
       " 'binary classification: i',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: Z',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: f',\n",
       " 'binary classification: i',\n",
       " 'binary classification: g',\n",
       " 'binary classification: u',\n",
       " 'binary classification: r',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: u',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification: e',\n",
       " 'binary classification: r',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: (',\n",
       " 'binary classification: $',\n",
       " 'binary classification: 4',\n",
       " 'binary classification: 0',\n",
       " 'binary classification: 0',\n",
       " 'binary classification: +',\n",
       " 'binary classification: )',\n",
       " 'binary classification: .',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: W',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: u',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification: .',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: A',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: l',\n",
       " 'binary classification: u',\n",
       " 'binary classification: c',\n",
       " 'binary classification: k',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification: k',\n",
       " 'binary classification: e',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: a',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: c',\n",
       " 'binary classification: o',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification: e',\n",
       " 'binary classification: c',\n",
       " 'binary classification: t',\n",
       " 'binary classification: i',\n",
       " 'binary classification: b',\n",
       " 'binary classification: l',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: f',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: r',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: k',\n",
       " 'binary classification: n',\n",
       " 'binary classification: o',\n",
       " 'binary classification: c',\n",
       " 'binary classification: k',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: d',\n",
       " 'binary classification: o',\n",
       " 'binary classification: w',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: f',\n",
       " 'binary classification: i',\n",
       " 'binary classification: g',\n",
       " 'binary classification: u',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: d',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: r',\n",
       " 'binary classification: o',\n",
       " 'binary classification: y',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: .',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: O',\n",
       " 'binary classification: b',\n",
       " 'binary classification: v',\n",
       " 'binary classification: i',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: s',\n",
       " 'binary classification: l',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: d',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: s',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: o',\n",
       " 'binary classification: m',\n",
       " 'binary classification: e',\n",
       " 'binary classification: n',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: f',\n",
       " 'binary classification: o',\n",
       " 'binary classification: r',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: u',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: a',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: l',\n",
       " 'binary classification: s',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: i',\n",
       " 'binary classification: m',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification: a',\n",
       " 'binary classification: l',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: p',\n",
       " 'binary classification: e',\n",
       " 'binary classification: r',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: p',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: c',\n",
       " 'binary classification: h',\n",
       " 'binary classification: i',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification: b',\n",
       " 'binary classification: b',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification: b',\n",
       " 'binary classification: b',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: c',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: i',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: v',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification: c',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: s',\n",
       " 'binary classification: a',\n",
       " 'binary classification: r',\n",
       " 'binary classification: i',\n",
       " 'binary classification: l',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: r',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: i',\n",
       " 'binary classification: g',\n",
       " 'binary classification: n',\n",
       " 'binary classification: i',\n",
       " 'binary classification: f',\n",
       " 'binary classification: i',\n",
       " 'binary classification: c',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: o',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification: r',\n",
       " 'binary classification: .',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: \\n',\n",
       " 'binary classification: O',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: c',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: r',\n",
       " 'binary classification: s',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: P',\n",
       " 'binary classification: R',\n",
       " 'binary classification: E',\n",
       " 'binary classification: F',\n",
       " 'binary classification: E',\n",
       " 'binary classification: R',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: h',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: l',\n",
       " 'binary classification: i',\n",
       " 'binary classification: k',\n",
       " 'binary classification: e',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: Z',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: n',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: d',\n",
       " 'binary classification: e',\n",
       " 'binary classification: f',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: u',\n",
       " 'binary classification: g',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: p',\n",
       " 'binary classification: l',\n",
       " 'binary classification: u',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: o',\n",
       " 'binary classification: o',\n",
       " 'binary classification: k',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: u',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: f',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: f',\n",
       " 'binary classification: a',\n",
       " 'binary classification: l',\n",
       " 'binary classification: l',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: l',\n",
       " 'binary classification: o',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: i',\n",
       " 'binary classification: r',\n",
       " 'binary classification: l',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification: n',\n",
       " \"binary classification: '\",\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: Z',\n",
       " 'binary classification: e',\n",
       " 'binary classification: l',\n",
       " 'binary classification: d',\n",
       " 'binary classification: a',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: u',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " \"binary classification: '\",\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: j',\n",
       " 'binary classification: u',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification: w',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " \"binary classification: '\",\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: o',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: e',\n",
       " 'binary classification: .',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " \"binary classification: '\",\n",
       " 'binary classification: m',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: l',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: n',\n",
       " 'binary classification: o',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: o',\n",
       " 'binary classification: i',\n",
       " 'binary classification: n',\n",
       " 'binary classification: g',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: o',\n",
       " 'binary classification: r',\n",
       " 'binary classification: r',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: u',\n",
       " 'binary classification: c',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: b',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: t',\n",
       " 'binary classification: o',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: b',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: o',\n",
       " 'binary classification: n',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: ,',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: h',\n",
       " 'binary classification: a',\n",
       " 'binary classification: v',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: e',\n",
       " 'binary classification: n',\n",
       " 'binary classification: o',\n",
       " 'binary classification: u',\n",
       " 'binary classification: g',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: o',\n",
       " 'binary classification: n',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: m',\n",
       " 'binary classification: y',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: p',\n",
       " 'binary classification: l',\n",
       " 'binary classification: a',\n",
       " 'binary classification: t',\n",
       " 'binary classification: e',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: w',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification: h',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: s',\n",
       " 'binary classification: t',\n",
       " 'binary classification: u',\n",
       " 'binary classification: d',\n",
       " 'binary classification: i',\n",
       " 'binary classification: e',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: a',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: t',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: i',\n",
       " 'binary classification: s',\n",
       " 'binary classification: .',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: P',\n",
       " 'binary classification: l',\n",
       " 'binary classification: u',\n",
       " 'binary classification: s',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: I',\n",
       " 'binary classification:  ',\n",
       " 'binary classification: g',\n",
       " 'binary classification: o',\n",
       " 'binary classification: t',\n",
       " 'binary classification: t',\n",
       " 'binary classification: a',\n",
       " 'binary classification:  ',\n",
       " ...]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2 = [PREFIX + doc for doc in train_dataset[0][\"post\"] + \"\\n\" + train_dataset[0][\"summary\"]]\n",
    "inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "015d431c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[14865, 13774, 10, 276, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 350, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 96, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 96, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 172, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 172, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 226, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 41, 1], [14865, 13774, 10, 1514, 1], [14865, 13774, 10, 314, 1], [14865, 13774, 10, 3, 632, 1], [14865, 13774, 10, 3, 632, 1], [14865, 13774, 10, 1768, 1], [14865, 13774, 10, 3, 61, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 549, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 71, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 411, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 411, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 276, 1], [14865, 13774, 10, 391, 1], [14865, 13774, 10, 262, 1], [14865, 13774, 10, 377, 1], [14865, 13774, 10, 262, 1], [14865, 13774, 10, 391, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 354, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 276, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 226, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 412, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 332, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 332, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 354, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 63, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 75, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 5, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 454, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 31, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 41, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 1824, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 51, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 6, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 354, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 102, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 55, 1], [14865, 13774, 10, 3, 61, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 208, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 27, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 52, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 210, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 7, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 23, 1], [14865, 13774, 10, 3, 157, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 17, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 115, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 107, 1], [14865, 13774, 10, 3, 76, 1], [14865, 13774, 10, 3, 122, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 29, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 3, 32, 1], [14865, 13774, 10, 3, 89, 1], [14865, 13774, 10, 1], [14865, 13774, 10, 1027, 1], [14865, 13774, 10, 3, 15, 1], [14865, 13774, 10, 3, 40, 1], [14865, 13774, 10, 3, 26, 1], [14865, 13774, 10, 3, 9, 1], [14865, 13774, 10, 3, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = tokenizer(inputs2)\n",
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee0d8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "label = \"1\"\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    label = tokenizer(label, max_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc931e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [209, 1], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21541d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fbe3a4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': Previous: Guys, I think I\\'m \"cured\" Previous: Guys, I'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22316cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../comparison_splits\"\n",
    "PREFIX = \"binary classifation: \"\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9639040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b1ddb1517d68537e\n",
      "Found cached dataset json (/home/ayushthakur/.cache/huggingface/datasets/json/default-b1ddb1517d68537e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b7830e36b0433b88a63b48a6af5141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-88724b549b3e0a85\n",
      "Found cached dataset json (/home/ayushthakur/.cache/huggingface/datasets/json/default-88724b549b3e0a85/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bcf80bf7f548fb90dca42730bed610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the dataset\n",
    "train_dataset = load_dataset(\"json\", data_files=f\"{DATA_PATH}/train.jsonl\")[\"train\"]\n",
    "valid_dataset = load_dataset(\"json\", data_files=f\"{DATA_PATH}/valid.jsonl\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2322e7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 't3_3pppzr',\n",
       " 'post': 'Previous: \\n\\nGuys, I think I\\'m \"cured\". It was a strange event but what the heck, it made me realize something.\\n\\nI was studying late at night in my room a few days ago. I have this shelf in my room with a bunch of zelda collectibles and a really expensive Zelda figurine underneath it ($400+).\\n\\nWell, guess what. As my luck would have it, Ikea shelf gave in, all my collectibles fell to the ground and the shelf knocked down my figure and destroyed it.\\n\\nObviously a distressing moment for me but it was also at that time I realised I needed to perhaps chill with this hobby and that the hobby can still be mine without having to necessarily share it with a significant other.\\n\\nOf course I would PREFER if she liked Zelda too and it would definitely be a huge plus in my book but if I fall in love with a girl who isn\\'t into Zelda, I guess that\\'s just how it\\'s going to be. I\\'m honestly not going to worry too much about this to be honest, I have enough on my plate with studies as it is. Plus I gotta take some extra shifts at work so I can replace my broken statue and collectibles. Unfortunately some of them can\\'t be bought anymore but oh well such is life.\\n\\nThanks everyone for reaching out to me and helping me. This has been an eye opener for me. I\\'m more than willing to date a girl who doesn\\'t care about Zelda because honestly, if she is just there for me and makes me happy, I feel that is all I could ask for. However if she happens to like Zelda too, then that\\'s great (not a requirement, just a plus!)',\n",
       " 'chosen': ' I have Zelda figurine and I need to find a girl to date that will also like Zelda but not be a huge fan of Zelda.',\n",
       " 'rejected': \" A part of my collection got destroyed. Made me realize perhaps I've been going a bit overboard. Will continue my hobby but it won't take over my dating life anymore.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f101bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da082e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    chosen_inputs = [post + \"\\n\" + summary for post, summary in zip(examples[\"post\"], examples[\"chosen\"])]\n",
    "    rejected_inputs = [post + \"\\n\" + summary for post, summary in zip(examples[\"post\"], examples[\"rejected\"])]\n",
    "    \n",
    "    inputs = [PREFIX + doc for doc in examples[\"post\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=550, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = examples[\"label\"]\n",
    "    labels = [str(label) for label in labels]\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(text_target=labels, max_length=3, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"choice\"] = examples[\"label\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63def692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240f164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa504cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9727701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e31f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c93889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-146c1daaf6dd79a6\n",
      "Found cached dataset json (/home/ayushthakur/.cache/huggingface/datasets/json/default-146c1daaf6dd79a6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96fe8def7074d35a600148853275771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8dfa26f346d28263\n",
      "Found cached dataset json (/home/ayushthakur/.cache/huggingface/datasets/json/default-8dfa26f346d28263/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef35aeb7691a46a39a482c340905ff2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ayushthakur/.cache/huggingface/datasets/json/default-146c1daaf6dd79a6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-f4ac9ac0bfa98b29.arrow\n",
      "Loading cached processed dataset at /home/ayushthakur/.cache/huggingface/datasets/json/default-8dfa26f346d28263/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-5821162798f4af06.arrow\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../comparison_splits\"\n",
    "PREFIX = \"binary classifation: \"\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Get the dataset\n",
    "train_dataset = load_dataset(\"json\", data_files=f\"{DATA_PATH}/train.jsonl\")[\"train\"]\n",
    "valid_dataset = load_dataset(\"json\", data_files=f\"{DATA_PATH}/valid.jsonl\")[\"train\"]\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [post + \"\\n\" + summary for post, summary in zip(examples[\"post\"], examples[\"summary\"])]\n",
    "    inputs = [PREFIX + doc for doc in examples[\"post\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=550, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = examples[\"label\"]\n",
    "    labels = [str(label) for label in labels]\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(text_target=labels, max_length=3, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"choice\"] = examples[\"label\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# # Remove unwanted columns\n",
    "train_dataset = train_dataset.remove_columns(['id', 'post', 'summary', 'label'])\n",
    "valid_dataset = valid_dataset.remove_columns(['id', 'post', 'summary', 'label'])\n",
    "\n",
    "# data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")\n",
    "# tf_train_set = model.prepare_tf_dataset(\n",
    "#     train_dataset,\n",
    "#     shuffle=True,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     collate_fn=data_collator,\n",
    "# )\n",
    "\n",
    "# # tf_valid_set = model.prepare_tf_dataset(\n",
    "# #     valid_dataset,\n",
    "# #     shuffle=False,\n",
    "# #     batch_size=BATCH_SIZE,\n",
    "# #     collate_fn=data_collator,\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ff96142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "trainloader = train_dataset.to_tf_dataset(\n",
    "#             columns=[\"choice\", \"input_ids\", \"attention_mask\"],\n",
    "#             label_cols=[\"labels\"],\n",
    "            batch_size=16,\n",
    "            shuffle=True,\n",
    "            collate_fn=data_collator,\n",
    "            prefetch=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dad528a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tf_utils import shape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a1ca743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shift_right(input_ids):\n",
    "    decoder_start_token_id = 0\n",
    "    pad_token_id = 0\n",
    "\n",
    "    assert decoder_start_token_id is not None, (\n",
    "        \"self.model.config.decoder_start_token_id has to be defined. In TF T5 it is usually set to the\"\n",
    "        \" pad_token_id. See T5 docs for more information\"\n",
    "    )\n",
    "\n",
    "    start_tokens = tf.fill((shape_list(input_ids)[0], 1), decoder_start_token_id)\n",
    "    start_tokens = tf.cast(start_tokens, input_ids.dtype)  # Ensure compatible dtypes for concatenation\n",
    "    shifted_input_ids = tf.concat([start_tokens, input_ids[:, :-1]], -1)\n",
    "\n",
    "    assert pad_token_id is not None, \"self.model.config.pad_token_id has to be defined.\"\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids = tf.where(\n",
    "        shifted_input_ids == -100,\n",
    "        tf.cast(tf.fill(shape_list(shifted_input_ids), pad_token_id), shifted_input_ids.dtype),\n",
    "        shifted_input_ids,\n",
    "    )\n",
    "\n",
    "    # \"Verify that `labels` has only positive values and -100\"\n",
    "    assert_gte0 = tf.debugging.assert_greater_equal(\n",
    "        shifted_input_ids, tf.constant(0, dtype=shifted_input_ids.dtype)\n",
    "    )\n",
    "\n",
    "    # Make sure the assertion op is called by wrapping the result in an identity no-op\n",
    "    with tf.control_dependencies([assert_gte0]):\n",
    "        shifted_input_ids = tf.identity(shifted_input_ids)\n",
    "\n",
    "    return shifted_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f295486e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'input_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'choice': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "482208c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(inputs):\n",
    "    # This will be used as decoder_input_ids\n",
    "    shift_right_labels = _shift_right(inputs[\"labels\"])\n",
    "    inputs[\"decoder_input_ids\"] = shift_right_labels\n",
    "    inputs.pop(\"labels\")\n",
    "\n",
    "    # This label is for calculating the accuracy of the reward model\n",
    "    labels = inputs[\"choice\"]\n",
    "    inputs.pop(\"choice\")\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f38a798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = trainloader.map(parse_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "trainloader = trainloader.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2392ae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': <tf.Tensor: shape=(16, 506), dtype=int64, numpy=\n",
       "  array([[14865,   853,    99, ...,     0,     0,     0],\n",
       "         [14865,   853,    99, ...,     0,     0,     0],\n",
       "         [14865,   853,    99, ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [14865,   853,    99, ...,     0,     0,     0],\n",
       "         [14865,   853,    99, ...,     0,     0,     0],\n",
       "         [14865,   853,    99, ...,     0,     0,     0]])>,\n",
       "  'attention_mask': <tf.Tensor: shape=(16, 506), dtype=int64, numpy=\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]])>,\n",
       "  'decoder_input_ids': <tf.Tensor: shape=(16, 3), dtype=int64, numpy=\n",
       "  array([[  0, 209,   1],\n",
       "         [  0, 209,   1],\n",
       "         [  0,   3, 632],\n",
       "         [  0, 209,   1],\n",
       "         [  0,   3, 632],\n",
       "         [  0, 209,   1],\n",
       "         [  0, 209,   1],\n",
       "         [  0,   3, 632],\n",
       "         [  0, 209,   1],\n",
       "         [  0,   3, 632],\n",
       "         [  0, 209,   1],\n",
       "         [  0, 209,   1],\n",
       "         [  0, 209,   1],\n",
       "         [  0,   3, 632],\n",
       "         [  0,   3, 632],\n",
       "         [  0,   3, 632]])>},\n",
       " <tf.Tensor: shape=(16,), dtype=int64, numpy=array([1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0])>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(trainloader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "008600ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5RewardModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(T5RewardModel, self).__init__()\n",
    "        config = T5Config()\n",
    "        self.t5_without_lm_head = TFT5Model(config)\n",
    "        self.reward_head = tf.keras.layers.Dense(1, use_bias=False, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        sequence_output = self.t5_without_lm_head(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            decoder_input_ids=inputs[\"decoder_input_ids\"],\n",
    "            training=training).last_hidden_state\n",
    "\n",
    "        reward_output = self.reward_head(sequence_output[:,0,:]) ## extract the 1st token's embeddings\n",
    "\n",
    "        return reward_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "866a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model = T5RewardModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a73d2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
       "array([[0.19765256],\n",
       "       [0.19703884],\n",
       "       [0.19661598],\n",
       "       [0.1970882 ],\n",
       "       [0.19656728],\n",
       "       [0.196947  ],\n",
       "       [0.19677263],\n",
       "       [0.197112  ],\n",
       "       [0.19760194],\n",
       "       [0.19729137],\n",
       "       [0.19713765],\n",
       "       [0.19740523],\n",
       "       [0.19686896],\n",
       "       [0.19787773],\n",
       "       [0.19810855],\n",
       "       [0.19713028]], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce4322aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ab62fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model.fit(trainloader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1870f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74109d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
