{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f3fc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c368c",
   "metadata": {},
   "source": [
    "# Fine tuning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81fd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"train.jsonl\"\n",
    "valid_file = \"valid.jsonl\"\n",
    "test_file = \"test.jsonl\"\n",
    "\n",
    "\n",
    "DATA_SIZE = 0.1 # we will use only 10% of the total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ba59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def sample_data(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "        size = int(len(json_list)*DATA_SIZE)\n",
    "        json_list = random.sample(json_list, size)\n",
    "        json_file.close()\n",
    "        \n",
    "    return json_list\n",
    "\n",
    "\n",
    "def write_samples_to_file(samples, dataset_type):\n",
    "    with open(f\"dataset_splits/{dataset_type}_{'_'.join(str(DATA_SIZE).split('.'))}.jsonl\", 'a') as outfile:\n",
    "        for json_str in samples:\n",
    "            sample = json.loads(json_str)\n",
    "            json.dump(sample, outfile)\n",
    "            outfile.write('\\n')\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e61bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = sample_data(train_file)\n",
    "valid_samples = sample_data(valid_file)\n",
    "test_samples = sample_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bcb66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_samples_to_file(train_samples, dataset_type=\"train\")\n",
    "write_samples_to_file(valid_samples, dataset_type=\"valid\")\n",
    "write_samples_to_file(test_samples, dataset_type=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d859ea",
   "metadata": {},
   "source": [
    "# Comparison dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baedf7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_files = glob.glob(\"comparisons/batch*.json\")\n",
    "comparison_files.remove(\"comparisons/batch0_cnndm.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4742338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 26.76it/s]\n"
     ]
    }
   ],
   "source": [
    "comparisons_list = []\n",
    "\n",
    "for comparison_file in tqdm(comparison_files): # iterate through all the files\n",
    "    with open(comparison_file, 'r') as dst_file:\n",
    "        dst_list = list(dst_file)\n",
    "        comparisons_list.extend(dst_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf08a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 176655/176655 [00:02<00:00, 75157.36it/s]\n"
     ]
    }
   ],
   "source": [
    "comparison_list_train_split = []\n",
    "comparison_list_valid1_split = []\n",
    "comparison_list_valid2_split = []\n",
    "\n",
    "split_names = []\n",
    "\n",
    "for comparison_str in tqdm(comparisons_list):\n",
    "    sample = json.loads(comparison_str)\n",
    "    split_name = sample[\"split\"]\n",
    "    if split_name == \"train\":\n",
    "        comparison_list_train_split.append(comparison_str)\n",
    "    elif split_name == \"valid1\":\n",
    "        comparison_list_valid1_split.append(comparison_str)\n",
    "    else:\n",
    "        comparison_list_valid2_split.append(comparison_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71b16c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92858, 33082, 50715)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comparison_list_train_split), len(comparison_list_valid1_split), len(comparison_list_valid2_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "068e3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 0.4 # Use 40% for comparison\n",
    "\n",
    "def sample_data(split):\n",
    "    size = int(len(split)*DATA_SIZE)\n",
    "    split = random.sample(split, size)\n",
    "\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75b5fb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37143, 13232, 20286)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_list_train_split = sample_data(comparison_list_train_split)\n",
    "comparison_list_valid1_split = sample_data(comparison_list_valid1_split)\n",
    "comparison_list_valid2_split = sample_data(comparison_list_valid2_split)\n",
    "\n",
    "len(comparison_list_train_split), len(comparison_list_valid1_split), len(comparison_list_valid2_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74148ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_samples_to_file(samples, dataset_type):\n",
    "    with open(f\"comparison_splits/{dataset_type}_{'_'.join(str(DATA_SIZE).split('.'))}.jsonl\", 'a') as outfile:\n",
    "        for json_str in samples:\n",
    "            sample = json.loads(json_str)\n",
    "            json.dump(sample, outfile)\n",
    "            outfile.write('\\n')\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "091d5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_samples_to_file(comparison_list_train_split, dataset_type=\"train\")\n",
    "write_samples_to_file(comparison_list_valid1_split, dataset_type=\"valid1\")\n",
    "write_samples_to_file(comparison_list_valid2_split, dataset_type=\"valid2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a88a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
